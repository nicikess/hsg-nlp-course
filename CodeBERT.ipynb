{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "mount_file_id": "1nInXTB3EG3g3zpJwfHI0LvvySxnIyS7H",
      "authorship_tag": "ABX9TyNQOZ6EFvMA7r6b+OZ1wRMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicikess/hsg-nlp-course/blob/main/CodeBERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References"
      ],
      "metadata": {
        "id": "YgrFUsZJAioe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "https://github.com/microsoft/CodeBERT/tree/master/CodeBERT/codesearch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "Kw1sIpBUAlsh",
        "outputId": "a3de32da-b680-4226-f673-95b79a0cf6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-4b2d07dc771a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    https://github.com/microsoft/CodeBERT/tree/master/CodeBERT/codesearch\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports for project"
      ],
      "metadata": {
        "id": "NMZGcfhW6Kw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import logging\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.utils.data import (DataLoader, RandomSampler, TensorDataset, Dataset, SequentialSampler)\n",
        "from tqdm import tqdm, trange\n",
        "from torch.nn import CrossEntropyLoss\n",
        "\n",
        "!pip install transformers\n",
        "from transformers import (AdamW,\n",
        "                          RobertaConfig,\n",
        "                          RobertaModel,\n",
        "                          RobertaForSequenceClassification,\n",
        "                          RobertaTokenizer, \n",
        "                          get_linear_schedule_with_warmup)\n",
        "\n",
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNVVCtR56LKA",
        "outputId": "c0bb3d8d-9829-4b68-f618-a21784aeefab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: utils in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger()\n",
        "logging.basicConfig(level=logging.DEBUG)"
      ],
      "metadata": {
        "id": "Urhj7ANl9Qh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set directories and file names"
      ],
      "metadata": {
        "id": "m00AapAe6FX8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb-sf0q9yYkh"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/NLP/data/'\n",
        "train_file = 'train.jsonl'\n",
        "eval_file = 'valid.jsonl'\n",
        "model_path = 'python_model/'\n",
        "model_config_path = 'python_model/config.json'\n",
        "output_dir = '/content/drive/MyDrive/NLP/data/output/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set seed"
      ],
      "metadata": {
        "id": "tiHjXq4M6Xfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init deterministic seed\n",
        "seed_value = 1234\n",
        "np.random.seed(seed_value) # set numpy seed\n",
        "torch.manual_seed(seed_value) # set pytorch seed CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6hSPfND6X37",
        "outputId": "a0b5fa93-95b8-4ac2-a871-de16217ca66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fcda9412670>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enable GPU"
      ],
      "metadata": {
        "id": "xjApSc9d6I8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "BK-hURoWndh9",
        "outputId": "be34f065-f404-442d-9916-4a2485debae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set cpu or gpu enabled device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu').type\n",
        "\n",
        "# init deterministic GPU seed\n",
        "torch.cuda.manual_seed(seed_value)\n",
        "\n",
        "# log type of device enabled\n",
        "print('[LOG] notebook with {} computation enabled'.format(str(device)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxLpBUlD27TH",
        "outputId": "cc7500bf-0f09-4b26-bc23-9c4e6096efec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LOG] notebook with cpu computation enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set hyperparameters"
      ],
      "metadata": {
        "id": "L36Puzgr7OU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "learning_rate = 2e-5\n",
        "num_training_epochs = 10\n",
        "#warmup_steps = 0\n",
        "#start_epoch = 0\n",
        "#gradient_accumulation_steps = 1\n",
        "#adam_epsilon = 1e-8"
      ],
      "metadata": {
        "id": "cMJPmJuR7My1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "YBSgbktLLijf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, tokenizer, file_path=None):\n",
        "        file_path = os.path.join(data_dir,file_path)\n",
        "        self.examples = []\n",
        "        data=[]\n",
        "        with open(file_path) as f:\n",
        "            for line in f:\n",
        "                line=line.strip()\n",
        "                js=json.loads(line)\n",
        "                data.append(js)\n",
        "\n",
        "        #for js in data:\n",
        "          #self.examples.append(convert_examples_to_features(js,tokenizer))\n",
        "\n",
        "        #np.save('/content/drive/MyDrive/NLP/data/examples.npy', self.examples)\n",
        "\n",
        "\n",
        "        logger.info(\"load examples\")\n",
        "        self.examples = np.load('/content/drive/MyDrive/NLP/data/examples.npy', allow_pickle=True)\n",
        "\n",
        "        ####TAKE OUT####    \n",
        "        if 'train' in file_path:\n",
        "            for idx, example in enumerate(self.examples[:3]):\n",
        "                logger.info(\"*** Example ***\")\n",
        "                logger.info(\"idx: {}\".format(idx))\n",
        "                logger.info(\"code_tokens: {}\".format([x.replace('\\u0120','_') for x in example.code_tokens]))\n",
        "                logger.info(\"code_ids: {}\".format(' '.join(map(str, example.code_ids))))\n",
        "                logger.info(\"nl_tokens: {}\".format([x.replace('\\u0120','_') for x in example.nl_tokens]))\n",
        "                logger.info(\"nl_ids: {}\".format(' '.join(map(str, example.nl_ids))))                             \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, i):   \n",
        "        return (torch.tensor(self.examples[i].code_ids),torch.tensor(self.examples[i].nl_ids))"
      ],
      "metadata": {
        "id": "d9cgqIe0HCD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert examples to features used in load data"
      ],
      "metadata": {
        "id": "k8T0ol1276U-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set maximum length for code and natural language\n",
        "code_length = 256\n",
        "nl_length = 128"
      ],
      "metadata": {
        "id": "JIxwiOxFNDT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single training/test features for a example.\"\"\"\n",
        "    def __init__(self,\n",
        "                 code_tokens,\n",
        "                 code_ids,\n",
        "                 nl_tokens,\n",
        "                 nl_ids,\n",
        "                 url,\n",
        "\n",
        "    ):\n",
        "        self.code_tokens = code_tokens\n",
        "        self.code_ids = code_ids\n",
        "        self.nl_tokens = nl_tokens\n",
        "        self.nl_ids = nl_ids\n",
        "        self.url=url"
      ],
      "metadata": {
        "id": "xODAy5Eajy40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_examples_to_features(js,tokenizer):\n",
        "    #code\n",
        "    code=' '.join(js['code_tokens'])\n",
        "    code_tokens=tokenizer.tokenize(code)[:code_length-2]\n",
        "    code_tokens =[tokenizer.cls_token]+code_tokens+[tokenizer.sep_token]\n",
        "    code_ids =  tokenizer.convert_tokens_to_ids(code_tokens)\n",
        "    padding_length = code_length - len(code_ids)\n",
        "    code_ids+=[tokenizer.pad_token_id]*padding_length\n",
        "    \n",
        "    nl=' '.join(js['docstring_tokens'])\n",
        "    nl_tokens=tokenizer.tokenize(nl)[:nl_length-2]\n",
        "    nl_tokens =[tokenizer.cls_token]+nl_tokens+[tokenizer.sep_token]\n",
        "    nl_ids =  tokenizer.convert_tokens_to_ids(nl_tokens)\n",
        "    padding_length = nl_length - len(nl_ids)\n",
        "    nl_ids+=[tokenizer.pad_token_id]*padding_length\n",
        "\n",
        "    return InputFeatures(code_tokens,code_ids,nl_tokens,nl_ids,js['url'])\n"
      ],
      "metadata": {
        "id": "M84JjFIi8AZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "QLKWl-9K69rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, tokenizer):\n",
        "\n",
        "  #Get the training dataset\n",
        "  train_dataset=TextDataset(tokenizer, train_file)\n",
        "  train_sampler = RandomSampler(train_dataset)\n",
        "  train_dataloader = DataLoader(train_dataset, sampler = train_sampler, batch_size = batch_size)\n",
        "\n",
        "  optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0,num_training_steps=len(train_dataloader)*num_training_epochs)\n",
        "\n",
        "  logger.info(\"Training start\")\n",
        "\n",
        "  model.zero_grad()\n",
        "  model.train()\n",
        "\n",
        "  tr_num,tr_loss,best_mrr=0,0,0\n",
        "\n",
        "  for idx in range(num_training_epochs):\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "      #Get inputs\n",
        "      code_inputs = batch[0].to(device)    \n",
        "      nl_inputs = batch[1].to(device)\n",
        "\n",
        "      #Get code and nl vectors\n",
        "      code_vec = model(code_inputs=code_inputs)\n",
        "      nl_vec = model(nl_inputs=nl_inputs)\n",
        "\n",
        "      #Calculate scores and loss\n",
        "      scores=torch.einsum(\"ab,cb->ac\",nl_vec,code_vec)\n",
        "      loss_fct = CrossEntropyLoss()\n",
        "      loss = loss_fct(scores, torch.arange(code_inputs.size(0), device=scores.device))\n",
        "\n",
        "      #Report loss\n",
        "      tr_loss += loss.item()\n",
        "      tr_num+=1\n",
        "      if (step+1)% 100==0:\n",
        "          logger.info(\"epoch {} step {} loss {}\".format(idx,step+1,round(tr_loss/tr_num,5)))\n",
        "          tr_loss=0\n",
        "          tr_num=0\n",
        "\n",
        "      #Backward\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      scheduler.step()\n",
        "\n",
        "    #evaluate    \n",
        "    results = evaluate(model, tokenizer, eval_file, eval_when_training=True)\n",
        "    for key, value in results.items():\n",
        "      logger.info(\"  %s = %s\", key, round(value,4))"
      ],
      "metadata": {
        "id": "gKB-F_YS6-Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate"
      ],
      "metadata": {
        "id": "VzsH88JkOfvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, tokenizer,file_name,eval_when_training=False):\n",
        "    query_dataset = TextDataset(tokenizer, file_name)\n",
        "    query_sampler = SequentialSampler(query_dataset)\n",
        "    query_dataloader = DataLoader(query_dataset, sampler=query_sampler, batch_size=batch_size,num_workers=4)\n",
        "    \n",
        "    code_dataset = TextDataset(tokenizer, args, args.codebase_file)\n",
        "    code_sampler = SequentialSampler(code_dataset)\n",
        "    code_dataloader = DataLoader(code_dataset, sampler=code_sampler, batch_size=batch_size,num_workers=4)    \n",
        "\n",
        "    # Eval!\n",
        "\n",
        "    #### TAKE OUT ####\n",
        "    logger.info(\"***** Running evaluation *****\")\n",
        "    logger.info(\"  Num queries = %d\", len(query_dataset))\n",
        "    logger.info(\"  Num codes = %d\", len(code_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "    code_vecs=[] \n",
        "    nl_vecs=[]\n",
        "    for batch in query_dataloader:  \n",
        "        nl_inputs = batch[1].to(args.device)\n",
        "        with torch.no_grad():\n",
        "            nl_vec = model(nl_inputs=nl_inputs) \n",
        "            nl_vecs.append(nl_vec.cpu().numpy()) \n",
        "\n",
        "    for batch in code_dataloader:\n",
        "        code_inputs = batch[0].to(device)    \n",
        "        with torch.no_grad():\n",
        "            code_vec= model(code_inputs=code_inputs)\n",
        "            code_vecs.append(code_vec.cpu().numpy())  \n",
        "    model.train()    \n",
        "    code_vecs=np.concatenate(code_vecs,0)\n",
        "    nl_vecs=np.concatenate(nl_vecs,0)\n",
        "\n",
        "    scores=np.matmul(nl_vecs,code_vecs.T)\n",
        "    \n",
        "    sort_ids=np.argsort(scores, axis=-1, kind='quicksort', order=None)[:,::-1]    \n",
        "    \n",
        "    nl_urls=[]\n",
        "    code_urls=[]\n",
        "    for example in query_dataset.examples:\n",
        "        nl_urls.append(example.url)\n",
        "        \n",
        "    for example in code_dataset.examples:\n",
        "        code_urls.append(example.url)\n",
        "        \n",
        "    ranks=[]\n",
        "    for url, sort_id in zip(nl_urls,sort_ids):\n",
        "        rank=0\n",
        "        find=False\n",
        "        for idx in sort_id[:1000]:\n",
        "            if find is False:\n",
        "                rank+=1\n",
        "            if code_urls[idx]==url:\n",
        "                find=True\n",
        "        if find:\n",
        "            ranks.append(1/rank)\n",
        "        else:\n",
        "            ranks.append(0)\n",
        "    \n",
        "    result = {\n",
        "        \"eval_mrr\":float(np.mean(ranks))\n",
        "    }\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "FuwZ9TxWOjsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):   \n",
        "    def __init__(self, encoder):\n",
        "        super(Model, self).__init__()\n",
        "        self.encoder = encoder\n",
        "      \n",
        "    def forward(self, code_inputs=None, nl_inputs=None): \n",
        "        if code_inputs is not None:\n",
        "            return self.encoder(code_inputs,attention_mask=code_inputs.ne(1))[1]\n",
        "        else:\n",
        "            return self.encoder(nl_inputs,attention_mask=nl_inputs.ne(1))[1]"
      ],
      "metadata": {
        "id": "HmeArHj7IN8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load model"
      ],
      "metadata": {
        "id": "H_C0seXHLl_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = RobertaConfig.from_pretrained(os.path.join(data_dir, model_config_path))\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "model = RobertaModel.from_pretrained(os.path.join(data_dir, model_path))    \n",
        "model = Model(model)\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "8jWEESe-Lu-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "WPBOxJizLwdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl43LuCKLNcl",
        "outputId": "e9545e7f-d536-490c-93a7-fdb45ddd1722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:load examples\n",
            "INFO:root:*** Example ***\n",
            "INFO:root:idx: 0\n",
            "INFO:root:code_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_\"', 's', '\"', '_)', '_:', '_level', '_=', '_level', '_+', '_\"', '__', '\"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_\"', ';\"', '_)', '_[', '_0', '_]', '</s>']\n",
            "INFO:root:code_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:root:nl_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']\n",
            "INFO:root:nl_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:root:*** Example ***\n",
            "INFO:root:idx: 1\n",
            "INFO:root:code_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_#', '_should', '_not', '_happen', '_with', '_os', '.', 'm', 'aked', 'irs', '_#', '_EN', 'O', 'ENT', ':', '_No', '_such', '_file', '_or', '_directory', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_\"\"\"', 'One', '_or', '_more', '_directories', '_in', '_the', '_path', '_({', '})', '_do', '_not', '_exist', '.', '_If', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_you', '_are', '_specifying', '_a', '_new', '_directory', '_for', '_output', ',', '_please', '_ensure', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_all', '_other', '_directories', '_in', '_the', '_path', '_currently', '_exist', '.\"', '\"\"', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_\"\"\"', 'An', '_error', '_occurred', '_trying', '_to', '_create', '_the', '_output', '_directory', 'Ċ', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_({', '})', '_with', '_message', ':', '_{}', '\"\"\"', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']\n",
            "INFO:root:code_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 849 197 45 1369 19 11988 4 119 8435 21098 849 13245 673 5382 35 440 215 2870 50 31826 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 49434 3762 50 55 44472 11 5 2718 49698 49424 109 45 5152 4 318 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 47 32 39140 10 92 31826 13 4195 6 2540 1306 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 70 97 44472 11 5 2718 855 5152 72 48149 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 49434 4688 5849 2756 667 7 1045 5 4195 31826 50118 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 1437 49698 49424 19 1579 35 49153 49849 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:root:nl_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']\n",
            "INFO:root:nl_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:root:*** Example ***\n",
            "INFO:root:idx: 2\n",
            "INFO:root:code_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_\"', 'r', 'U', '\"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_\"', 'Input', '_file', '_is', '_closed', '.\"', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']\n",
            "INFO:root:code_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:root:nl_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']\n",
            "INFO:root:nl_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "INFO:root:Training start\n"
          ]
        }
      ]
    }
  ]
}