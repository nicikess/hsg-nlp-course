{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicikess/hsg-nlp-course/blob/main/notebooks/convertion_docstrings_to_vectors\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ah255YEHU0c"
      },
      "source": [
        "# Semantic Code Search using Transformers and BERT - Part II\n",
        "Author - Shashank Ramesh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alpXXR6bHU0g"
      },
      "source": [
        "Part-II uses docstrings from the data collected and processed in part-I and converts them to vectors using ALBERT."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LwnOGN1DxqR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEjq8hpYHU0g"
      },
      "source": [
        "## Converting Docstrings to vectors\n",
        "This notebook contains steps to fine-tune ALBERT model to generate docstring vectors"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/NLP/model/docstrings.txt', 'w') as f:\n",
        "    for item in train_df['docstring_tokens'].values:  # Write only the docstrings into a txt file\n",
        "        f.write(\"%s\\n\" % item) # One docstring per line\n"
      ],
      "metadata": {
        "id": "O7z6VR1Jrb70"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHyyxqZ8HU0g"
      },
      "source": [
        "<img src=\"images/3.png\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7s5TYp3q-oMx",
        "outputId": "44870361-936a-4bc6-f701-c0b32d69f975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: albert-tensorflow in /usr/local/lib/python3.7/dist-packages (1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from albert-tensorflow) (1.15.0)\n",
            "\u001b[31mERROR: Invalid requirement: 'sentencepiece$'\u001b[0m\n",
            "Collecting tensorflow==1.15.0\n",
            "  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 27 kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 33.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.37.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
            "\u001b[K     |████████████████████████████████| 503 kB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.44.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (1.14.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.10.0.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.0) (1.5.2)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=ce4e9864662b25f449d3196c3b6faa514d3716eaac819f33e4b56d1d14005707\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, gast, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.8.0\n",
            "    Uninstalling tensorboard-2.8.0:\n",
            "      Successfully uninstalled tensorboard-2.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.8.0\n",
            "    Uninstalling tensorflow-2.8.0:\n",
            "      Successfully uninstalled tensorflow-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#importing libraries\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import csv\n",
        "import pandas as pd\n",
        "import transformers\n",
        "from transformers import  AlbertConfig,TFAlbertModel\n",
        "from transformers import AlbertTokenizer\n",
        "from transformers import  AlbertConfig,TFAlbertModel\n",
        "\n",
        "!pip install transformers\n",
        "!pip install albert-tensorflow\n",
        "!pip install sentencepiece$\n",
        "!pip install tensorflow==1.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dq7grXZOHU0i"
      },
      "source": [
        "### Creating training data to fine-tune ALBERT\n",
        "For incremental training on a pre-trained ALBERT model we need to process our docstrings for the model to train on. We need to generate masks and create sentence pairs for the model to train on using the n-gram Masked Language Modelling and Sentence Order Prediction tasks "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNyTKe5Q-60v",
        "outputId": "a349d1c8-daf2-497a-e67d-99068f0e06cd",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/tokenization.py:240: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0412 16:55:27.646852 140629329467264 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/tokenization.py:240: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:loading sentence piece model\n",
            "I0412 16:55:27.647172 140629329467264 tokenization.py:240] loading sentence piece model\n",
            "INFO:tensorflow:*** Reading from input files ***\n",
            "I0412 16:55:27.911050 140629329467264 create_pretraining_data.py:631] *** Reading from input files ***\n",
            "INFO:tensorflow:  /content/drive/MyDrive/NLP/model/docstrings.txt\n",
            "I0412 16:55:27.911398 140629329467264 create_pretraining_data.py:633]   /content/drive/MyDrive/NLP/model/docstrings.txt\n",
            "INFO:tensorflow:number of instances: 126930\n",
            "I0412 16:58:57.091158 140629329467264 create_pretraining_data.py:641] number of instances: 126930\n",
            "INFO:tensorflow:*** Writing to output files ***\n",
            "I0412 16:58:57.091616 140629329467264 create_pretraining_data.py:644] *** Writing to output files ***\n",
            "INFO:tensorflow:  /content/drive/MyDrive/NLP/model/tf_examples\n",
            "I0412 16:58:57.091759 140629329467264 create_pretraining_data.py:646]   /content/drive/MyDrive/NLP/model/tf_examples\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.097673 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁true ▁if ▁processing ▁get ter ▁for ▁the ▁column ▁values [SEP] [MASK] [MASK] acher [MASK] [MASK] ▁check ▁syntax ▁graceful ▁exit ▁for ▁components ▁the ▁intervals ▁taken ▁this ▁method ▁must ▁be ▁o tower ▁ver written ▁ conf ▁id ▁to ▁detect ▁changes ▁a ▁un qi ue [MASK] ▁for ▁this ▁app ▁so [MASK] [SEP]\n",
            "I0412 16:58:57.097941 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁true ▁if ▁processing ▁get ter ▁for ▁the ▁column ▁values [SEP] [MASK] [MASK] acher [MASK] [MASK] ▁check ▁syntax ▁graceful ▁exit ▁for ▁components ▁the ▁intervals ▁taken ▁this ▁method ▁must ▁be ▁o tower ▁ver written ▁ conf ▁id ▁to ▁detect ▁changes ▁a ▁un qi ue [MASK] ▁for ▁this ▁app ▁so [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 1151 100 5511 164 815 26 14 4698 4070 3 4 4 19789 4 4 2631 22649 22609 4350 26 5090 14 15899 658 48 2109 491 44 635 17183 2494 6390 13 14093 4924 20 9092 1693 21 367 9142 4185 4 26 48 4865 86 4 3\n",
            "I0412 16:58:57.098159 140629329467264 create_pretraining_data.py:200] input_ids: 2 1151 100 5511 164 815 26 14 4698 4070 3 4 4 19789 4 4 2631 22649 22609 4350 26 5090 14 15899 658 48 2109 491 44 635 17183 2494 6390 13 14093 4924 20 9092 1693 21 367 9142 4185 4 26 48 4865 86 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.098345 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.098548 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.098761 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 11 12 13 14 15 16 43 48\n",
            "I0412 16:58:57.098905 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 11 12 13 14 15 16 43 48\n",
            "INFO:tensorflow:masked_lm_ids: 253 2125 1289 56 129 2631 204 30\n",
            "I0412 16:58:57.099050 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 253 2125 1289 56 129 2631 204 30\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.099240 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0412 16:58:57.099385 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.099914 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁started ▁directory ▁where ▁resources ▁like [MASK] ▁to ▁run ▁for [MASK] [MASK] [MASK] ▁expected ▁called ▁before ▁http adapt er ▁optional ▁field ▁for [MASK] ▁gastropod ▁address ▁receive ▁the ▁value ▁from ▁the ▁pir ▁sensor ▁my s ql ▁connector ▁already [MASK] [MASK] ▁my s ql [SEP] ▁return ▁times tam ps ▁as ▁strings [SEP]\n",
            "I0412 16:58:57.100101 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁started ▁directory ▁where ▁resources ▁like [MASK] ▁to ▁run ▁for [MASK] [MASK] [MASK] ▁expected ▁called ▁before ▁http adapt er ▁optional ▁field ▁for [MASK] ▁gastropod ▁address ▁receive ▁the ▁value ▁from ▁the ▁pir ▁sensor ▁my s ql ▁connector ▁already [MASK] [MASK] ▁my s ql [SEP] ▁return ▁times tam ps ▁as ▁strings [SEP]\n",
            "INFO:tensorflow:input_ids: 2 373 16755 113 2566 101 4 20 485 26 4 4 4 1727 227 115 7775 27576 106 12832 575 26 4 11079 3218 2588 14 1923 37 14 9242 14865 51 18 22402 17991 614 4 4 51 18 22402 3 788 436 4919 1919 28 7887 3\n",
            "I0412 16:58:57.100294 140629329467264 create_pretraining_data.py:200] input_ids: 2 373 16755 113 2566 101 4 20 485 26 4 4 4 1727 227 115 7775 27576 106 12832 575 26 4 11079 3218 2588 14 1923 37 14 9242 14865 51 18 22402 17991 614 4 4 51 18 22402 3 788 436 4919 1919 28 7887 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.100460 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.100667 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1\n",
            "I0412 16:58:57.100848 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 6 10 11 12 22 23 37 38\n",
            "I0412 16:58:57.101005 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 6 10 11 12 22 23 37 38\n",
            "INFO:tensorflow:masked_lm_ids: 17113 48 1289 50 14 446 8406 18\n",
            "I0412 16:58:57.101159 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 17113 48 1289 50 14 446 8406 18\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.101341 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.101500 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.102058 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁the ▁ser p ▁is ▁sufficiently ▁attractive ▁enough [MASK] [MASK] [MASK] ▁perfect ▁judgement s ▁that ▁is ▁judgement s ▁from ▁the ▁tre c ▁q rel s ▁add ▁command ▁line ▁flags ▁for [SEP] ▁a ▁dj ango ▁common ▁user ▁search ▁image ▁file name ▁in [MASK] [MASK] [MASK] ▁1849 [MASK] ▁sy s ▁path [SEP]\n",
            "I0412 16:58:57.102245 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁the ▁ser p ▁is ▁sufficiently ▁attractive ▁enough [MASK] [MASK] [MASK] ▁perfect ▁judgement s ▁that ▁is ▁judgement s ▁from ▁the ▁tre c ▁q rel s ▁add ▁command ▁line ▁flags ▁for [SEP] ▁a ▁dj ango ▁common ▁user ▁search ▁image ▁file name ▁in [MASK] [MASK] [MASK] ▁1849 [MASK] ▁sy s ▁path [SEP]\n",
            "INFO:tensorflow:input_ids: 2 14 4245 306 25 14476 7982 511 4 4 4 2107 17872 18 30 25 17872 18 37 14 4607 150 2593 7256 18 3547 1202 293 9318 26 3 21 3857 14541 757 4155 2122 1961 3893 7259 19 4 4 4 9810 4 10315 18 2013 3\n",
            "I0412 16:58:57.102435 140629329467264 create_pretraining_data.py:200] input_ids: 2 14 4245 306 25 14476 7982 511 4 4 4 2107 17872 18 30 25 17872 18 37 14 4607 150 2593 7256 18 3547 1202 293 9318 26 3 21 3857 14541 757 4155 2122 1961 3893 7259 19 4 4 4 9810 4 10315 18 2013 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.102632 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.102804 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            "I0412 16:58:57.102972 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 9 10 41 42 43 44 45\n",
            "I0412 16:58:57.103117 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 8 9 10 41 42 43 44 45\n",
            "INFO:tensorflow:masked_lm_ids: 20 2830 2027 10315 18 1961 8353 54\n",
            "I0412 16:58:57.103269 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 20 2830 2027 10315 18 1961 8353 54\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.103424 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0412 16:58:57.103588 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.104046 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁alpha ▁in [MASK] ▁bohemian ▁compute ▁the ▁jac card ▁need ham ▁dis similar ity ▁between ▁two ▁boo le an ▁1 [MASK] d ▁array s ▁draws ▁and ▁updates ▁the [MASK] [MASK] ▁the ▁blend [SEP] ▁send ▁a ▁single [MASK] [MASK] ▁return ▁node ▁with ▁key ▁that ▁is ▁successor ▁of ▁current ▁node ▁key [SEP]\n",
            "I0412 16:58:57.104217 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁alpha ▁in [MASK] ▁bohemian ▁compute ▁the ▁jac card ▁need ham ▁dis similar ity ▁between ▁two ▁boo le an ▁1 [MASK] d ▁array s ▁draws ▁and ▁updates ▁the [MASK] [MASK] ▁the ▁blend [SEP] ▁send ▁a ▁single [MASK] [MASK] ▁return ▁node ▁with ▁key ▁that ▁is ▁successor ▁of ▁current ▁node ▁key [SEP]\n",
            "INFO:tensorflow:input_ids: 2 5705 19 4 18778 23909 14 12548 6648 376 1225 1460 19107 856 128 81 9827 413 210 137 4 43 7718 18 10802 17 16779 14 4 4 14 11138 3 2660 21 345 4 4 788 15421 29 1246 30 25 4558 16 866 15421 1246 3\n",
            "I0412 16:58:57.104435 140629329467264 create_pretraining_data.py:200] input_ids: 2 5705 19 4 18778 23909 14 12548 6648 376 1225 1460 19107 856 128 81 9827 413 210 137 4 43 7718 18 10802 17 16779 14 4 4 14 11138 3 2660 21 345 4 4 788 15421 29 1246 30 25 4558 16 866 15421 1246 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.104650 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.104853 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.105022 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 4 20 21 28 29 36 37\n",
            "I0412 16:58:57.105173 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 3 4 20 21 28 29 36 37\n",
            "INFO:tensorflow:masked_lm_ids: 683 713 13 43 4113 19 2802 4851\n",
            "I0412 16:58:57.105372 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 683 713 13 43 4113 19 2802 4851\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.105555 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.105721 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.106167 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁file ▁directory [MASK] [MASK] ▁gi [MASK] ▁gi ▁suite ▁options ▁are ▁provided ▁raise ▁a ▁permanent ▁error ▁if ▁cd b ▁status ▁is ▁not ▁none ▁context ▁manager ▁to ▁request [MASK] ▁when ▁an ▁gilded ▁is ▁raised [SEP] ▁1 ▁m ▁sum ▁i ▁1 ori ▁ [MASK] ▁pre d ▁i ▁ y ▁i ▁2 [SEP]\n",
            "I0412 16:58:57.106343 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁file ▁directory [MASK] [MASK] ▁gi [MASK] ▁gi ▁suite ▁options ▁are ▁provided ▁raise ▁a ▁permanent ▁error ▁if ▁cd b ▁status ▁is ▁not ▁none ▁context ▁manager ▁to ▁request [MASK] ▁when ▁an ▁gilded ▁is ▁raised [SEP] ▁1 ▁m ▁sum ▁i ▁1 ori ▁ [MASK] ▁pre d ▁i ▁ y ▁i ▁2 [SEP]\n",
            "INFO:tensorflow:input_ids: 2 3893 16755 4 4 4100 4 4100 6160 6368 50 1173 3972 21 3032 7019 100 1745 220 1782 25 52 2369 4141 1382 20 3772 4 76 40 26792 25 1127 3 137 307 3907 31 137 5985 13 4 782 43 31 13 93 31 172 3\n",
            "I0412 16:58:57.106549 140629329467264 create_pretraining_data.py:200] input_ids: 2 3893 16755 4 4 4100 4 4100 6160 6368 50 1173 3972 21 3032 7019 100 1745 220 1782 25 52 2369 4141 1382 20 3772 4 76 40 26792 25 1127 3 137 307 3907 31 137 5985 13 4 782 43 31 13 93 31 172 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.106735 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.106910 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1\n",
            "I0412 16:58:57.107084 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 3 4 6 27 30 39 40 41\n",
            "I0412 16:58:57.107233 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 3 4 6 27 30 39 40 41\n",
            "INFO:tensorflow:masked_lm_ids: 1206 76 1289 747 5391 307 13 93\n",
            "I0412 16:58:57.107385 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 1206 76 1289 747 5391 307 13 93\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.107559 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.107737 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.108204 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁the ▁value ▁of ▁the ▁keys ▁input ▁for ▁this ▁chor eo ▁conditional ▁string ▁a ▁comm a [MASK] ▁list ▁of ▁keys ▁to [MASK] [MASK] ▁unless ▁specify [SEP] [MASK] ▁and ▁retrieve s ▁the [MASK] ▁id ▁set ▁the ▁value ▁of ▁the ▁thread id ▁input ▁for ▁this ▁chor eo [MASK] ▁string ▁the ▁thread [SEP]\n",
            "I0412 16:58:57.108377 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁the ▁value ▁of ▁the ▁keys ▁input ▁for ▁this ▁chor eo ▁conditional ▁string ▁a ▁comm a [MASK] ▁list ▁of ▁keys ▁to [MASK] [MASK] ▁unless ▁specify [SEP] [MASK] ▁and ▁retrieve s ▁the [MASK] ▁id ▁set ▁the ▁value ▁of ▁the ▁thread id ▁input ▁for ▁this ▁chor eo [MASK] ▁string ▁the ▁thread [SEP]\n",
            "INFO:tensorflow:input_ids: 2 14 1923 16 14 5534 6367 26 48 12024 3894 21206 3724 21 11951 58 4 968 16 5534 20 4 4 4003 19077 3 4 17 11917 18 14 4 4924 309 14 1923 16 14 9322 1340 6367 26 48 12024 3894 4 3724 14 9322 3\n",
            "I0412 16:58:57.108594 140629329467264 create_pretraining_data.py:200] input_ids: 2 14 1923 16 14 5534 6367 26 48 12024 3894 21206 3724 21 11951 58 4 968 16 5534 20 4 4 4003 19077 3 4 17 11917 18 14 4 4924 309 14 1923 16 14 9322 1340 6367 26 48 12024 3894 4 3724 14 9322 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.108777 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.108954 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
            "I0412 16:58:57.109126 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 8 16 21 22 26 31 35 45\n",
            "I0412 16:58:57.114280 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 8 16 21 22 26 31 35 45\n",
            "INFO:tensorflow:masked_lm_ids: 48 4196 27448 1390 3896 3723 1923 12832\n",
            "I0412 16:58:57.114825 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 48 4196 27448 1390 3896 3723 1923 12832\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.115036 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.115230 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.116006 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁videos ▁listing ▁checks ▁if ▁the ▁local ▁copy ▁of ▁the ▁zo tero ▁database ▁is ▁up ▁to [MASK] ▁if ▁not ▁the [MASK] ▁is ▁also ▁index ed [SEP] [MASK] [MASK] [MASK] [MASK] ▁image ▁random ▁dot ▁stereo gram [MASK] ▁expand ▁via ▁encode ▁p ng ▁j pg ▁op ▁functional ▁test ▁for ▁text ▁paragraph [SEP]\n",
            "I0412 16:58:57.116233 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁videos ▁listing ▁checks ▁if ▁the ▁local ▁copy ▁of ▁the ▁zo tero ▁database ▁is ▁up ▁to [MASK] ▁if ▁not ▁the [MASK] ▁is ▁also ▁index ed [SEP] [MASK] [MASK] [MASK] [MASK] ▁image ▁random ▁dot ▁stereo gram [MASK] ▁expand ▁via ▁encode ▁p ng ▁j pg ▁op ▁functional ▁test ▁for ▁text ▁paragraph [SEP]\n",
            "INFO:tensorflow:input_ids: 2 6610 9554 16602 100 14 375 4344 16 14 9017 16059 6018 25 71 20 4 100 52 14 4 25 67 4348 69 3 4 4 4 4 1961 5477 14123 10994 6295 4 6073 1197 20523 351 2723 487 9623 3088 7652 1289 26 1854 20599 3\n",
            "I0412 16:58:57.116530 140629329467264 create_pretraining_data.py:200] input_ids: 2 6610 9554 16602 100 14 375 4344 16 14 9017 16059 6018 25 71 20 4 100 52 14 4 25 67 4348 69 3 4 4 4 4 1961 5477 14123 10994 6295 4 6073 1197 20523 351 2723 487 9623 3088 7652 1289 26 1854 20599 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.116845 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.117061 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.117280 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 16 20 26 27 28 29 35 36\n",
            "I0412 16:58:57.117471 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 16 20 26 27 28 29 35 36\n",
            "INFO:tensorflow:masked_lm_ids: 1231 1054 5196 18 21 345 26 7487\n",
            "I0412 16:58:57.117707 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 1231 1054 5196 18 21 345 26 7487\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.117913 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.118111 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.118799 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁dispatch ▁to ▁the ▁right [MASK] [SEP] [MASK] ▁from ▁and ro guard ▁and ▁perform ▁enumerat ion ▁tasks ▁that ▁helps ▁build ▁the ▁attack surface ▁for ▁the ▁target ▁a pk ▁create ▁gr 3 ▁me she s [MASK] [MASK] ▁contains ▁the ▁me sh ▁data ▁and ▁in [MASK] ▁settings ▁is [MASK] [MASK] ▁me [SEP]\n",
            "I0412 16:58:57.119016 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁dispatch ▁to ▁the ▁right [MASK] [SEP] [MASK] ▁from ▁and ro guard ▁and ▁perform ▁enumerat ion ▁tasks ▁that ▁helps ▁build ▁the ▁attack surface ▁for ▁the ▁target ▁a pk ▁create ▁gr 3 ▁me she s [MASK] [MASK] ▁contains ▁the ▁me sh ▁data ▁and ▁in [MASK] ▁settings ▁is [MASK] [MASK] ▁me [SEP]\n",
            "INFO:tensorflow:input_ids: 2 14226 20 14 193 4 3 4 37 17 661 9499 17 2985 26940 872 8674 30 7778 1895 14 991 18830 26 14 2935 21 17244 1600 7711 240 55 1079 18 4 4 1588 14 55 1635 1054 17 19 4 12410 25 4 4 55 3\n",
            "I0412 16:58:57.119254 140629329467264 create_pretraining_data.py:200] input_ids: 2 14226 20 14 193 4 3 4 37 17 661 9499 17 2985 26940 872 8674 30 7778 1895 14 991 18830 26 14 2935 21 17244 1600 7711 240 55 1079 18 4 4 1588 14 55 1635 1054 17 19 4 12410 25 4 4 55 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.119502 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.119788 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.120041 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 7 34 35 36 43 46 47\n",
            "I0412 16:58:57.120257 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 5 7 34 35 36 43 46 47\n",
            "INFO:tensorflow:masked_lm_ids: 1028 587 1119 1736 1588 1119 9931 56\n",
            "I0412 16:58:57.120453 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 1028 587 1119 1736 1588 1119 9931 56\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.120677 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0412 16:58:57.120868 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.121561 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁make ▁sure ▁there ▁are ▁no ▁kernel s ▁running ▁at ▁the ▁start ▁re cursive ly ▁build ▁up ▁the ▁method [MASK] ▁to ▁pass ▁to ▁the [MASK] [MASK] ▁on ▁a ▁part ic ual ▁virtual ▁machine [SEP] ▁revert ▁to ▁the [MASK] ▁backed ▁up ▁state ▁re cursive ly em ▁an ▁add [MASK] ▁chain [SEP]\n",
            "I0412 16:58:57.121781 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁make ▁sure ▁there ▁are ▁no ▁kernel s ▁running ▁at ▁the ▁start ▁re cursive ly ▁build ▁up ▁the ▁method [MASK] ▁to ▁pass ▁to ▁the [MASK] [MASK] ▁on ▁a ▁part ic ual ▁virtual ▁machine [SEP] ▁revert ▁to ▁the [MASK] ▁backed ▁up ▁state ▁re cursive ly em ▁an ▁add [MASK] ▁chain [SEP]\n",
            "INFO:tensorflow:input_ids: 2 233 562 80 50 90 17007 18 946 35 14 799 302 24244 102 1895 71 14 2109 4 20 1477 20 14 4 4 27 21 141 596 6948 6599 1940 3 24156 20 14 4 6334 71 146 302 24244 102 1503 40 3547 4 2858 3\n",
            "I0412 16:58:57.122033 140629329467264 create_pretraining_data.py:200] input_ids: 2 233 562 80 50 90 17007 18 946 35 14 799 302 24244 102 1895 71 14 2109 4 20 1477 20 14 4 4 27 21 141 596 6948 6599 1940 3 24156 20 14 4 6334 71 146 302 24244 102 1503 40 3547 4 2858 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.122232 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.122412 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1\n",
            "I0412 16:58:57.122601 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 19 24 25 37 44 46 47 48\n",
            "I0412 16:58:57.122747 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 19 24 25 37 44 46 47 48\n",
            "INFO:tensorflow:masked_lm_ids: 204 8128 2844 236 15810 3547 218 2858\n",
            "I0412 16:58:57.122896 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 204 8128 2844 236 15810 3547 218 2858\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.123049 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.123191 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.123654 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁using ▁the ▁data ▁held ▁by ▁this ▁instance ▁that ▁is ▁ evaluate ▁the ▁background [MASK] ▁profile ▁the ▁trigger ▁kernel ▁at ▁events [MASK] [MASK] ▁prediction ▁time ▁optional ly ▁you [MASK] ▁limit ▁the ▁data ▁used ▁though ▁this ▁is ▁against ▁the [SEP] ▁tests ▁the ▁get file entry by path s pec [MASK] [SEP]\n",
            "I0412 16:58:57.123825 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁using ▁the ▁data ▁held ▁by ▁this ▁instance ▁that ▁is ▁ evaluate ▁the ▁background [MASK] ▁profile ▁the ▁trigger ▁kernel ▁at ▁events [MASK] [MASK] ▁prediction ▁time ▁optional ly ▁you [MASK] ▁limit ▁the ▁data ▁used ▁though ▁this ▁is ▁against ▁the [SEP] ▁tests ▁the ▁get file entry by path s pec [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 568 14 1054 269 34 48 4851 30 25 13 15599 14 2395 4 5296 14 7286 17007 35 963 4 4 13823 85 12832 102 42 4 4496 14 1054 147 362 48 25 149 14 3 4894 14 164 16877 18195 779 8353 18 12610 4 3\n",
            "I0412 16:58:57.124026 140629329467264 create_pretraining_data.py:200] input_ids: 2 568 14 1054 269 34 48 4851 30 25 13 15599 14 2395 4 5296 14 7286 17007 35 963 4 4 13823 85 12832 102 42 4 4496 14 1054 147 362 48 25 149 14 3 4894 14 164 16877 18195 779 8353 18 12610 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.124193 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.124357 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1\n",
            "I0412 16:58:57.124530 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 14 15 21 22 28 29 30 48\n",
            "I0412 16:58:57.124677 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 14 15 21 22 28 29 30 48\n",
            "INFO:tensorflow:masked_lm_ids: 1684 3123 115 14 92 4496 14 1990\n",
            "I0412 16:58:57.124824 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 1684 3123 115 14 92 4496 14 1990\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.124972 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.125113 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.125549 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁format ting ▁when ▁dumping [MASK] [MASK] ▁to ▁string [MASK] ▁trailing ▁spaces ▁and ▁lack s ▁a ▁new ▁line ▁at ▁the ▁end ▁this [MASK] ▁fix es [SEP] ed [MASK] ▁all ▁sub re source ▁entities ▁of ▁a ▁given [MASK] [MASK] ▁the ▁current ▁directory ▁if ▁needed ▁insert ▁text ▁an not ations ▁into [SEP]\n",
            "I0412 16:58:57.125748 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁format ting ▁when ▁dumping [MASK] [MASK] ▁to ▁string [MASK] ▁trailing ▁spaces ▁and ▁lack s ▁a ▁new ▁line ▁at ▁the ▁end ▁this [MASK] ▁fix es [SEP] ed [MASK] ▁all ▁sub re source ▁entities ▁of ▁a ▁given [MASK] [MASK] ▁the ▁current ▁directory ▁if ▁needed ▁insert ▁text ▁an not ations ▁into [SEP]\n",
            "INFO:tensorflow:input_ids: 2 2595 1203 76 26523 4 4 20 3724 4 14323 7644 17 1792 18 21 78 293 35 14 241 48 4 6098 160 3 69 4 65 972 99 12097 12549 16 21 504 4 4 14 866 16755 100 851 14692 1854 40 1270 7504 77 3\n",
            "I0412 16:58:57.125940 140629329467264 create_pretraining_data.py:200] input_ids: 2 2595 1203 76 26523 4 4 20 3724 4 14323 7644 17 1792 18 21 78 293 35 14 241 48 4 6098 160 3 69 4 65 972 99 12097 12549 16 21 504 4 4 14 866 16755 100 851 14692 1854 40 1270 7504 77 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.126152 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.126358 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            "I0412 16:58:57.126594 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 6 9 22 27 36 37 38\n",
            "I0412 16:58:57.126746 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 5 6 9 22 27 36 37 38\n",
            "INFO:tensorflow:masked_lm_ids: 487 528 63 1990 968 6577 1302 14\n",
            "I0412 16:58:57.126891 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 487 528 63 1990 968 6577 1302 14\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.127053 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.127216 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.127736 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁real ▁path ▁of ▁the ▁home ▁directory ▁sets ▁the ▁envelope [MASK] [MASK] [MASK] ▁of ▁this ▁envelope s information ▁remove ▁the ▁tick ▁labels ▁on ▁the ▁x ▁axis ▁but ▁leave ▁the [SEP] ▁enable ▁using ▁roster ▁version ing ▁check ▁whatever ▁platform ▁is ▁alive ▁attach ▁stool ▁lot [MASK] ▁summa ries [MASK] ▁a ▁tensor [SEP]\n",
            "I0412 16:58:57.127920 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁real ▁path ▁of ▁the ▁home ▁directory ▁sets ▁the ▁envelope [MASK] [MASK] [MASK] ▁of ▁this ▁envelope s information ▁remove ▁the ▁tick ▁labels ▁on ▁the ▁x ▁axis ▁but ▁leave ▁the [SEP] ▁enable ▁using ▁roster ▁version ing ▁check ▁whatever ▁platform ▁is ▁alive ▁attach ▁stool ▁lot [MASK] ▁summa ries [MASK] ▁a ▁tensor [SEP]\n",
            "INFO:tensorflow:input_ids: 2 683 2013 16 14 213 16755 3415 14 9127 4 4 4 16 48 9127 18 22793 4681 14 8809 13173 27 14 993 8577 47 767 14 3 9240 568 8699 615 68 2631 2099 2452 25 2481 19514 14689 865 4 18074 2829 4 21 24883 3\n",
            "I0412 16:58:57.128107 140629329467264 create_pretraining_data.py:200] input_ids: 2 683 2013 16 14 213 16755 3415 14 9127 4 4 4 16 48 9127 18 22793 4681 14 8809 13173 27 14 993 8577 47 767 14 3 9240 568 8699 615 68 2631 2099 2452 25 2481 19514 14689 865 4 18074 2829 4 21 24883 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.128280 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.128445 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            "I0412 16:58:57.128643 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 10 11 12 19 41 42 43 46\n",
            "I0412 16:58:57.128787 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 10 11 12 19 41 42 43 46\n",
            "INFO:tensorflow:masked_lm_ids: 12799 1782 160 14 21 865 16 20\n",
            "I0412 16:58:57.128938 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 12799 1782 160 14 21 865 16 20\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.129092 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.129232 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.129736 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁this ▁is ▁used ▁in ▁fe g t ▁fitness ▁ensemble ▁global ▁test [SEP] ▁in [MASK] ▁to ▁local ▁database ▁in [MASK] [MASK] ▁of ▁internet ▁connection ▁get ▁the ▁ rs r ▁fil name [MASK] [MASK] ▁and ▁instrument [MASK] ▁patronage ▁download ▁if ▁not ▁available ▁handle ▁key ▁press ▁events ▁things ▁done ▁by ▁this [SEP]\n",
            "I0412 16:58:57.129901 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁this ▁is ▁used ▁in ▁fe g t ▁fitness ▁ensemble ▁global ▁test [SEP] ▁in [MASK] ▁to ▁local ▁database ▁in [MASK] [MASK] ▁of ▁internet ▁connection ▁get ▁the ▁ rs r ▁fil name [MASK] [MASK] ▁and ▁instrument [MASK] ▁patronage ▁download ▁if ▁not ▁available ▁handle ▁key ▁press ▁events ▁things ▁done ▁by ▁this [SEP]\n",
            "INFO:tensorflow:input_ids: 2 48 25 147 19 3686 263 38 11331 5756 2062 1289 3 19 4 20 375 6018 19 4 4 16 2620 2760 164 14 13 1224 139 10853 7259 4 4 17 5529 4 17469 7121 100 52 904 3053 1246 901 963 564 677 34 48 3\n",
            "I0412 16:58:57.130093 140629329467264 create_pretraining_data.py:200] input_ids: 2 48 25 147 19 3686 263 38 11331 5756 2062 1289 3 19 4 20 375 6018 19 4 4 16 2620 2760 164 14 13 1224 139 10853 7259 4 4 17 5529 4 17469 7121 100 52 904 3053 1246 901 963 564 677 34 48 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.130312 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.130513 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.130708 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 14 19 20 31 32 35 36 46\n",
            "I0412 16:58:57.130863 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 14 19 20 31 32 35 36 46\n",
            "INFO:tensorflow:masked_lm_ids: 3878 13 13000 37 2452 1817 17 677\n",
            "I0412 16:58:57.131011 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 3878 13 13000 37 2452 1817 17 677\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.131160 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.131299 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.131769 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁return ▁a ▁ni ft i ▁containing ▁z ▁scores ▁for ▁connectivity ▁to ▁a ▁defined ▁seed ▁region [SEP] ▁and ▁a ▁ t cp ▁server ▁main ▁entry ▁point ▁defines ▁and ▁runs ▁the ▁word count ▁pipeline [MASK] ▁the ▁ex ecu table ▁to [MASK] [MASK] [MASK] ▁a ▁list ▁of [MASK] [MASK] [MASK] [MASK] [SEP]\n",
            "I0412 16:58:57.131938 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁return ▁a ▁ni ft i ▁containing ▁z ▁scores ▁for ▁connectivity ▁to ▁a ▁defined ▁seed ▁region [SEP] ▁and ▁a ▁ t cp ▁server ▁main ▁entry ▁point ▁defines ▁and ▁runs ▁the ▁word count ▁pipeline [MASK] ▁the ▁ex ecu table ▁to [MASK] [MASK] [MASK] ▁a ▁list ▁of [MASK] [MASK] [MASK] [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 788 21 1781 3072 49 3503 2052 7369 26 24026 20 21 2811 5134 632 3 17 21 13 38 7439 8128 407 2792 454 13110 17 1461 14 833 16549 12250 4 14 1396 17194 5924 20 4 4 4 21 968 16 4 4 4 4 3\n",
            "I0412 16:58:57.132154 140629329467264 create_pretraining_data.py:200] input_ids: 2 788 21 1781 3072 49 3503 2052 7369 26 24026 20 21 2811 5134 632 3 17 21 13 38 7439 8128 407 2792 454 13110 17 1461 14 833 16549 12250 4 14 1396 17194 5924 20 4 4 4 21 968 16 4 4 4 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.132324 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.132501 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1\n",
            "I0412 16:58:57.132697 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 0 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 33 39 40 41 45 46 47 48\n",
            "I0412 16:58:57.132859 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 33 39 40 41 45 46 47 48\n",
            "INFO:tensorflow:masked_lm_ids: 788 170 27 17 6368 302 14706 18\n",
            "I0412 16:58:57.222244 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 788 170 27 17 6368 302 14706 18\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.222619 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.222839 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.223757 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] ▁report [MASK] 90 ▁format ▁formats ▁are ▁x ls ▁tx t ▁and ▁xml ▁return ▁a [MASK] [MASK] ▁j son ▁files ▁to ▁read ▁setup [MASK] [MASK] ▁if ▁executed [SEP] ▁variance ▁of ▁recall ▁probability ▁now ▁c ette ▁ fon c tion ▁sup prime ▁le ▁mon stre ▁des [MASK] ▁list es [SEP]\n",
            "I0412 16:58:57.224009 140629329467264 create_pretraining_data.py:190] tokens: [CLS] [MASK] ▁report [MASK] 90 ▁format ▁formats ▁are ▁x ls ▁tx t ▁and ▁xml ▁return ▁a [MASK] [MASK] ▁j son ▁files ▁to ▁read ▁setup [MASK] [MASK] ▁if ▁executed [SEP] ▁variance ▁of ▁recall ▁probability ▁now ▁c ette ▁ fon c tion ▁sup prime ▁le ▁mon stre ▁des [MASK] ▁list es [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 1330 4 3165 2595 13767 50 993 7532 20225 38 17 23504 788 21 4 4 487 528 6488 20 1302 18161 4 4 100 5557 3 24619 16 7111 10177 130 272 3286 13 10229 150 3309 11128 21108 1009 3521 11278 1746 4 968 160 3\n",
            "I0412 16:58:57.224274 140629329467264 create_pretraining_data.py:200] input_ids: 2 4 1330 4 3165 2595 13767 50 993 7532 20225 38 17 23504 788 21 4 4 487 528 6488 20 1302 18161 4 4 100 5557 3 24619 16 7111 10177 130 272 3286 13 10229 150 3309 11128 21108 1009 3521 11278 1746 4 968 160 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.224502 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.224752 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1\n",
            "I0412 16:58:57.225024 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 3 4 16 17 24 25 46\n",
            "I0412 16:58:57.225229 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 1 3 4 16 17 24 25 46\n",
            "INFO:tensorflow:masked_lm_ids: 6036 4758 27 968 16 2017 4104 172\n",
            "I0412 16:58:57.225424 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 6036 4758 27 968 16 2017 4104 172\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.225666 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.225894 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.226646 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁merge s ▁the ▁u rl ▁extracted ▁from ▁dj ango ▁user ▁accounts ▁the ▁run ▁run time [MASK] [MASK] ▁default ing ▁to ▁run ▁as ▁unicode ▁string [SEP] ▁u rl ▁in [MASK] ▁browser ▁simple [MASK] [MASK] ▁dj ango ▁ s ▁log in ▁view ▁test ▁that ▁baldwin ▁navigation ▁is ▁successful ▁berkshire [MASK] [SEP]\n",
            "I0412 16:58:57.226924 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁merge s ▁the ▁u rl ▁extracted ▁from ▁dj ango ▁user ▁accounts ▁the ▁run ▁run time [MASK] [MASK] ▁default ing ▁to ▁run ▁as ▁unicode ▁string [SEP] ▁u rl ▁in [MASK] ▁browser ▁simple [MASK] [MASK] ▁dj ango ▁ s ▁log in ▁view ▁test ▁that ▁baldwin ▁navigation ▁is ▁successful ▁berkshire [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 12666 18 14 287 6362 18607 37 3857 14541 4155 5310 14 485 485 891 4 4 12838 68 20 485 28 28010 3724 3 287 6362 19 4 16495 1935 4 4 3857 14541 13 18 6738 108 1418 1289 30 11674 8368 25 1300 17422 4 3\n",
            "I0412 16:58:57.227190 140629329467264 create_pretraining_data.py:200] input_ids: 2 12666 18 14 287 6362 18607 37 3857 14541 4155 5310 14 485 485 891 4 4 12838 68 20 485 28 28010 3724 3 287 6362 19 4 16495 1935 4 4 3857 14541 13 18 6738 108 1418 1289 30 11674 8368 25 1300 17422 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.227415 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.227690 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.227941 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 0 1 1 0 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 16 17 29 32 33 43 47 48\n",
            "I0412 16:58:57.228156 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 16 17 29 32 33 43 47 48\n",
            "INFO:tensorflow:masked_lm_ids: 16755 2013 14 28051 140 2478 75 13\n",
            "I0412 16:58:57.228351 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 16755 2013 14 28051 140 2478 75 13\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.228575 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0412 16:58:57.228765 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.232425 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁order ▁account ▁symbol ▁price ▁quantity ▁field ▁returns ▁the ▁number ▁of ▁seconds [MASK] [MASK] [MASK] ▁took ▁along ▁with ▁the ▁result ▁two ▁nodes ▁are ▁equal ▁if ▁they ▁have ▁the ▁same ▁r data [SEP] ▁test ▁if ▁we ▁can ▁generate ▁multiple ▁input [MASK] ▁changing ▁some ▁variables ▁process ▁push [MASK] [MASK] [MASK] [MASK] [SEP]\n",
            "I0412 16:58:57.232651 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁order ▁account ▁symbol ▁price ▁quantity ▁field ▁returns ▁the ▁number ▁of ▁seconds [MASK] [MASK] [MASK] ▁took ▁along ▁with ▁the ▁result ▁two ▁nodes ▁are ▁equal ▁if ▁they ▁have ▁the ▁same ▁r data [SEP] ▁test ▁if ▁we ▁can ▁generate ▁multiple ▁input [MASK] ▁changing ▁some ▁variables ▁process ▁push [MASK] [MASK] [MASK] [MASK] [SEP]\n",
            "INFO:tensorflow:input_ids: 2 389 2176 4678 2162 12881 575 4815 14 234 16 2582 4 4 4 199 303 29 14 829 81 16272 50 2747 100 59 57 14 205 761 18768 3 1289 100 95 92 7920 1886 6367 4 4226 109 12157 953 3250 4 4 4 4 3\n",
            "I0412 16:58:57.232856 140629329467264 create_pretraining_data.py:200] input_ids: 2 389 2176 4678 2162 12881 575 4815 14 234 16 2582 4 4 4 199 303 29 14 829 81 16272 50 2747 100 59 57 14 205 761 18768 3 1289 100 95 92 7920 1886 6367 4 4226 109 12157 953 3250 4 4 4 4 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.233037 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.233206 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            "I0412 16:58:57.233373 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1\n",
            "INFO:tensorflow:masked_lm_positions: 12 13 14 39 45 46 47 48\n",
            "I0412 16:58:57.233558 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 12 13 14 39 45 46 47 48\n",
            "INFO:tensorflow:masked_lm_ids: 30 21 1990 6488 2741 20378 4235 263\n",
            "I0412 16:58:57.233736 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 30 21 1990 6488 2741 20378 4235 263\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.233887 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.234033 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.234523 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] [MASK] ▁method [MASK] ▁kw arg s ▁for ▁all ▁readers [SEP] [MASK] s ▁o au th 2 ▁consumer ▁object [MASK] ▁signal ▁and ▁leave ▁quietly ▁create ▁a ▁new ▁instance ▁dallas ▁the ▁get pri cing by pre fix ▁chor eo ▁a ▁tem boo ses sion ▁object [MASK] ▁a ▁valid ▁set ▁of [SEP]\n",
            "I0412 16:58:57.234712 140629329467264 create_pretraining_data.py:190] tokens: [CLS] [MASK] ▁method [MASK] ▁kw arg s ▁for ▁all ▁readers [SEP] [MASK] s ▁o au th 2 ▁consumer ▁object [MASK] ▁signal ▁and ▁leave ▁quietly ▁create ▁a ▁new ▁instance ▁dallas ▁the ▁get pri cing by pre fix ▁chor eo ▁a ▁tem boo ses sion ▁object [MASK] ▁a ▁valid ▁set ▁of [SEP]\n",
            "INFO:tensorflow:input_ids: 2 4 2109 4 3510 10663 18 26 65 7807 3 4 18 635 1346 96 135 6461 3095 4 2800 17 767 3721 1600 21 78 4851 4707 14 164 6944 6302 779 3515 18594 12024 3894 21 13449 10858 7202 5991 3095 4 21 7394 309 16 3\n",
            "I0412 16:58:57.234932 140629329467264 create_pretraining_data.py:200] input_ids: 2 4 2109 4 3510 10663 18 26 65 7807 3 4 18 635 1346 96 135 6461 3095 4 2800 17 767 3721 1600 21 78 4851 4707 14 164 6944 6302 779 3515 18594 12024 3894 21 13449 10858 7202 5991 3095 4 21 7394 309 16 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.235106 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.235274 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.235439 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 1 3 11 12 19 20 28 44\n",
            "I0412 16:58:57.235629 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 1 3 11 12 19 20 28 44\n",
            "INFO:tensorflow:masked_lm_ids: 15644 29 188 18 3683 2800 16 3503\n",
            "I0412 16:58:57.235787 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 15644 29 188 18 3683 2800 16 3503\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.235934 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0412 16:58:57.236074 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.236508 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁gives ▁a ▁path ▁representation [MASK] ▁the ▁focus ▁in ▁the ▁hive [MASK] ▁out [MASK] [MASK] ▁and [MASK] [MASK] ▁score [SEP] ▁return [MASK] ▁py game ▁surface ▁with ▁all ▁pixel s ▁turned ▁off ▁returns ▁all ▁v ouch ers ▁sent ▁out ▁by ▁user ▁provides ▁a [MASK] ▁of ▁the ▁key ▁value ▁pairs ▁in [SEP]\n",
            "I0412 16:58:57.236714 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁gives ▁a ▁path ▁representation [MASK] ▁the ▁focus ▁in ▁the ▁hive [MASK] ▁out [MASK] [MASK] ▁and [MASK] [MASK] ▁score [SEP] ▁return [MASK] ▁py game ▁surface ▁with ▁all ▁pixel s ▁turned ▁off ▁returns ▁all ▁v ouch ers ▁sent ▁out ▁by ▁user ▁provides ▁a [MASK] ▁of ▁the ▁key ▁value ▁pairs ▁in [SEP]\n",
            "INFO:tensorflow:input_ids: 2 2352 21 2013 5442 4 14 1776 19 14 25535 4 70 4 4 17 4 4 1618 3 788 4 7103 5128 1490 29 65 18146 18 412 168 4815 65 566 21554 445 795 70 34 4155 1927 21 4 16 14 1246 1923 7473 19 3\n",
            "I0412 16:58:57.236934 140629329467264 create_pretraining_data.py:200] input_ids: 2 2352 21 2013 5442 4 14 1776 19 14 25535 4 70 4 4 17 4 4 1618 3 788 4 7103 5128 1490 29 65 18146 18 412 168 4815 65 566 21554 445 795 70 34 4155 1927 21 4 16 14 1246 1923 7473 19 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.237097 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.237258 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.237418 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 5 11 13 14 16 17 21 42\n",
            "I0412 16:58:57.237615 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 5 11 13 14 16 17 21 42\n",
            "INFO:tensorflow:masked_lm_ids: 16 21062 2424 1633 4815 78 21 9186\n",
            "I0412 16:58:57.237777 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 16 21062 2424 1633 4815 78 21 9186\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.237945 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 1\n",
            "I0412 16:58:57.238089 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 1\n",
            "INFO:tensorflow:*** Example ***\n",
            "I0412 16:58:57.238534 140629329467264 create_pretraining_data.py:188] *** Example ***\n",
            "INFO:tensorflow:tokens: [CLS] ▁same ▁as [MASK] [MASK] [MASK] ▁a ▁new ▁line ▁after ▁the ▁trace [MASK] ▁calculate ▁the ▁numerical ▁in verse ▁of ▁f [SEP] ▁the ▁blog ▁post ▁given ▁by ▁post ▁id ▁replace [MASK] [MASK] ▁a ▁mapping ▁object ▁self ▁with ▁other ▁has ▁if ▁both [MASK] ▁same ▁keys ▁on ▁update ▁otherwise ▁just ▁keep ▁the [SEP]\n",
            "I0412 16:58:57.238723 140629329467264 create_pretraining_data.py:190] tokens: [CLS] ▁same ▁as [MASK] [MASK] [MASK] ▁a ▁new ▁line ▁after ▁the ▁trace [MASK] ▁calculate ▁the ▁numerical ▁in verse ▁of ▁f [SEP] ▁the ▁blog ▁post ▁given ▁by ▁post ▁id ▁replace [MASK] [MASK] ▁a ▁mapping ▁object ▁self ▁with ▁other ▁has ▁if ▁both [MASK] ▁same ▁keys ▁on ▁update ▁otherwise ▁just ▁keep ▁the [SEP]\n",
            "INFO:tensorflow:input_ids: 2 205 28 4 4 4 21 78 293 75 14 5565 4 18469 14 16010 19 9453 16 398 3 14 8146 678 504 34 678 4924 3934 4 4 21 13305 3095 1119 29 89 63 100 156 4 205 5534 27 11100 3190 114 643 14 3\n",
            "I0412 16:58:57.238928 140629329467264 create_pretraining_data.py:200] input_ids: 2 205 28 4 4 4 21 78 293 75 14 5565 4 18469 14 16010 19 9453 16 398 3 14 8146 678 504 34 678 4924 3934 4 4 21 13305 3095 1119 29 89 63 100 156 4 205 5534 27 11100 3190 114 643 14 3\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.239107 140629329467264 create_pretraining_data.py:200] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.239280 140629329467264 create_pretraining_data.py:200] segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "I0412 16:58:57.239443 140629329467264 create_pretraining_data.py:200] token_boundary: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:masked_lm_positions: 2 3 4 5 12 29 30 40\n",
            "I0412 16:58:57.239631 140629329467264 create_pretraining_data.py:200] masked_lm_positions: 2 3 4 5 12 29 30 40\n",
            "INFO:tensorflow:masked_lm_ids: 28 5565 47 5196 1474 1923 16 57\n",
            "I0412 16:58:57.239778 140629329467264 create_pretraining_data.py:200] masked_lm_ids: 28 5565 47 5196 1474 1923 16 57\n",
            "INFO:tensorflow:masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "I0412 16:58:57.239928 140629329467264 create_pretraining_data.py:200] masked_lm_weights: 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0\n",
            "INFO:tensorflow:next_sentence_labels: 0\n",
            "I0412 16:58:57.240086 140629329467264 create_pretraining_data.py:200] next_sentence_labels: 0\n",
            "INFO:tensorflow:Wrote 126930 total instances\n",
            "I0412 16:59:33.620214 140629329467264 create_pretraining_data.py:205] Wrote 126930 total instances\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/drive/MyDrive/NLP/model/create_pretraining_data.py\" \\\n",
        "  --input_file  \"/content/drive/MyDrive/NLP/model/docstrings.txt\" \\\n",
        "  --output_file  \"/content/drive/MyDrive/NLP/model/tf_examples\" \\\n",
        "  --vocab_file  \"/content/drive/MyDrive/NLP/model/30k-clean.vocab\" \\\n",
        "  --spm_model_file \"/content/drive/MyDrive/NLP/model/30k-clean.model\" \\\n",
        "  --do_lower_case True \\\n",
        "  --max_seq_length 50 \\\n",
        "  --max_predictions_per_seq 8 \\\n",
        "  --random_seed 12345 \\\n",
        "  --dupe_factor 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dZWehglHU0j"
      },
      "source": [
        "### Running incremental training to fine-tune ALBERT\n",
        "Once we have generated the training data from the above process we can begin the training process by running the run_pretraining.py file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJEkkWIMt53G",
        "outputId": "2fcfc3ae-7691-4e07-f110-34b9e58d6a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/lamb_optimizer.py:34: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:116: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0412 17:12:46.112170 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:116: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:*** Input Files ***\n",
            "I0412 17:12:46.117604 140454666205056 run_pretraining.py:484] *** Input Files ***\n",
            "INFO:tensorflow:  /content/drive/MyDrive/NLP/model/tf_examples\n",
            "I0412 17:12:46.117788 140454666205056 run_pretraining.py:486]   /content/drive/MyDrive/NLP/model/tf_examples\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbdb716ca70>) includes params argument, but params are not passed to Estimator.\n",
            "W0412 17:12:46.118480 140454666205056 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fbdb716ca70>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/MyDrive/NLP/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbdb5da1f50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "I0412 17:12:46.119420 140454666205056 estimator.py:212] Using config: {'_model_dir': '/content/drive/MyDrive/NLP/model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbdb5da1f50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0412 17:12:46.119763 140454666205056 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0412 17:12:46.120091 140454666205056 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
            "INFO:tensorflow:***** Running training *****\n",
            "I0412 17:12:46.120252 140454666205056 run_pretraining.py:527] ***** Running training *****\n",
            "INFO:tensorflow:  Batch size = 64\n",
            "I0412 17:12:46.120407 140454666205056 run_pretraining.py:528]   Batch size = 64\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0412 17:12:46.126665 140454666205056 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0412 17:12:46.127152 140454666205056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/NLP/model/run_pretraining.py:431: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0412 17:12:46.193139 140454666205056 deprecation.py:323] From /content/drive/MyDrive/NLP/model/run_pretraining.py:431: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0412 17:12:46.193421 140454666205056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/NLP/model/run_pretraining.py:448: map_and_batch_with_legacy_function (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch()\n",
            "W0412 17:12:46.210328 140454666205056 deprecation.py:323] From /content/drive/MyDrive/NLP/model/run_pretraining.py:448: map_and_batch_with_legacy_function (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch()\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/NLP/model/run_pretraining.py:464: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0412 17:12:46.411268 140454666205056 deprecation.py:323] From /content/drive/MyDrive/NLP/model/run_pretraining.py:464: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:<DatasetV1Adapter shapes: {input_ids: (64, 50), input_mask: (64, 50), masked_lm_ids: (64, 8), masked_lm_positions: (64, 8), masked_lm_weights: (64, 8), next_sentence_labels: (64, 1), segment_ids: (64, 50)}, types: {input_ids: tf.int32, input_mask: tf.int32, masked_lm_ids: tf.int32, masked_lm_positions: tf.int32, masked_lm_weights: tf.float32, next_sentence_labels: tf.int32, segment_ids: tf.int32}>\n",
            "I0412 17:12:46.423914 140454666205056 run_pretraining.py:449] <DatasetV1Adapter shapes: {input_ids: (64, 50), input_mask: (64, 50), masked_lm_ids: (64, 8), masked_lm_positions: (64, 8), masked_lm_weights: (64, 8), next_sentence_labels: (64, 1), segment_ids: (64, 50)}, types: {input_ids: tf.int32, input_mask: tf.int32, masked_lm_ids: tf.int32, masked_lm_positions: tf.int32, masked_lm_weights: tf.float32, next_sentence_labels: tf.int32, segment_ids: tf.int32}>\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0412 17:12:46.432726 140454666205056 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Running train on CPU\n",
            "I0412 17:12:46.433256 140454666205056 tpu_estimator.py:3124] Running train on CPU\n",
            "INFO:tensorflow:*** Features ***\n",
            "I0412 17:12:46.433735 140454666205056 run_pretraining.py:141] *** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (64, 50)\n",
            "I0412 17:12:46.433953 140454666205056 run_pretraining.py:143]   name = input_ids, shape = (64, 50)\n",
            "INFO:tensorflow:  name = input_mask, shape = (64, 50)\n",
            "I0412 17:12:46.434138 140454666205056 run_pretraining.py:143]   name = input_mask, shape = (64, 50)\n",
            "INFO:tensorflow:  name = masked_lm_ids, shape = (64, 8)\n",
            "I0412 17:12:46.434312 140454666205056 run_pretraining.py:143]   name = masked_lm_ids, shape = (64, 8)\n",
            "INFO:tensorflow:  name = masked_lm_positions, shape = (64, 8)\n",
            "I0412 17:12:46.434482 140454666205056 run_pretraining.py:143]   name = masked_lm_positions, shape = (64, 8)\n",
            "INFO:tensorflow:  name = masked_lm_weights, shape = (64, 8)\n",
            "I0412 17:12:46.434669 140454666205056 run_pretraining.py:143]   name = masked_lm_weights, shape = (64, 8)\n",
            "INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)\n",
            "I0412 17:12:46.434836 140454666205056 run_pretraining.py:143]   name = next_sentence_labels, shape = (64, 1)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (64, 50)\n",
            "I0412 17:12:46.435002 140454666205056 run_pretraining.py:143]   name = segment_ids, shape = (64, 50)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:194: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0412 17:12:46.435299 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:194: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:507: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0412 17:12:46.437144 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:507: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:588: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0412 17:12:46.463614 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:588: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:1025: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0412 17:12:46.518311 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:1025: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:253: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0412 17:12:47.974781 140454666205056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/albert/modeling.py:253: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0412 17:12:47.975837 140454666205056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "I0412 17:12:48.107570 140454666205056 run_pretraining.py:211] **** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "I0412 17:12:48.107872 140454666205056 run_pretraining.py:217]   name = bert/embeddings/word_embeddings:0, shape = (30000, 128)\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "I0412 17:12:48.108078 140454666205056 run_pretraining.py:217]   name = bert/embeddings/token_type_embeddings:0, shape = (2, 128)\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "I0412 17:12:48.108312 140454666205056 run_pretraining.py:217]   name = bert/embeddings/position_embeddings:0, shape = (512, 128)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "I0412 17:12:48.108590 140454666205056 run_pretraining.py:217]   name = bert/embeddings/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "I0412 17:12:48.108784 140454666205056 run_pretraining.py:217]   name = bert/embeddings/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "I0412 17:12:48.108959 140454666205056 run_pretraining.py:217]   name = bert/encoder/embedding_hidden_mapping_in/kernel:0, shape = (128, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "I0412 17:12:48.109169 140454666205056 run_pretraining.py:217]   name = bert/encoder/embedding_hidden_mapping_in/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "I0412 17:12:48.109344 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "I0412 17:12:48.109543 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/query/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "I0412 17:12:48.109714 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "I0412 17:12:48.109896 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/key/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "I0412 17:12:48.110069 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "I0412 17:12:48.110249 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/self/value/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "I0412 17:12:48.110428 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "I0412 17:12:48.110638 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/attention_1/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "I0412 17:12:48.110814 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "I0412 17:12:48.110984 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "I0412 17:12:48.111170 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/kernel:0, shape = (768, 3072)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "I0412 17:12:48.111353 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/dense/bias:0, shape = (3072,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "I0412 17:12:48.111541 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/kernel:0, shape = (3072, 768)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "I0412 17:12:48.111751 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/ffn_1/intermediate/output/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "I0412 17:12:48.111933 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/beta:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "I0412 17:12:48.112140 140454666205056 run_pretraining.py:217]   name = bert/encoder/transformer/group_0/inner_group_0/LayerNorm_1/gamma:0, shape = (768,)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "I0412 17:12:48.112377 140454666205056 run_pretraining.py:217]   name = bert/pooler/dense/kernel:0, shape = (768, 768)\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "I0412 17:12:48.112691 140454666205056 run_pretraining.py:217]   name = bert/pooler/dense/bias:0, shape = (768,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "I0412 17:12:48.112933 140454666205056 run_pretraining.py:217]   name = cls/predictions/transform/dense/kernel:0, shape = (768, 128)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "I0412 17:12:48.113169 140454666205056 run_pretraining.py:217]   name = cls/predictions/transform/dense/bias:0, shape = (128,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "I0412 17:12:48.113394 140454666205056 run_pretraining.py:217]   name = cls/predictions/transform/LayerNorm/beta:0, shape = (128,)\n",
            "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "I0412 17:12:48.113690 140454666205056 run_pretraining.py:217]   name = cls/predictions/transform/LayerNorm/gamma:0, shape = (128,)\n",
            "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (30000,)\n",
            "I0412 17:12:48.113957 140454666205056 run_pretraining.py:217]   name = cls/predictions/output_bias:0, shape = (30000,)\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "I0412 17:12:48.114211 140454666205056 run_pretraining.py:217]   name = cls/seq_relationship/output_weights:0, shape = (2, 768)\n",
            "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "I0412 17:12:48.114664 140454666205056 run_pretraining.py:217]   name = cls/seq_relationship/output_bias:0, shape = (2,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:36: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0412 17:12:48.115024 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:36: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:41: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "W0412 17:12:48.116760 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:41: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:53: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0412 17:12:48.125928 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:53: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:++++++ warmup starts at step 0, for 1000 steps ++++++\n",
            "I0412 17:12:48.126197 140454666205056 optimization.py:54] ++++++ warmup starts at step 0, for 1000 steps ++++++\n",
            "INFO:tensorflow:using lamb\n",
            "I0412 17:12:48.137030 140454666205056 optimization.py:87] using lamb\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:101: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0412 17:12:48.137338 140454666205056 module_wrapper.py:139] From /usr/local/lib/python3.7/dist-packages/albert/optimization.py:101: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0412 17:12:48.334257 140454666205056 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0412 17:12:52.347218 140454666205056 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0412 17:12:52.348861 140454666205056 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0412 17:12:53.318615 140454666205056 monitored_session.py:240] Graph was finalized.\n",
            "2022-04-12 17:12:53.454854: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0412 17:12:54.502793 140454666205056 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0412 17:12:54.590985 140454666205056 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/MyDrive/NLP/model/model.ckpt.\n",
            "I0412 17:12:57.748636 140454666205056 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /content/drive/MyDrive/NLP/model/model.ckpt.\n",
            "INFO:tensorflow:global_step/sec: 0.226699\n",
            "I0412 17:13:07.645950 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.226699\n",
            "INFO:tensorflow:examples/sec: 14.5088\n",
            "I0412 17:13:07.646606 140454666205056 tpu_estimator.py:2308] examples/sec: 14.5088\n",
            "INFO:tensorflow:global_step/sec: 0.83734\n",
            "I0412 17:13:08.840201 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.83734\n",
            "INFO:tensorflow:examples/sec: 53.5897\n",
            "I0412 17:13:08.840554 140454666205056 tpu_estimator.py:2308] examples/sec: 53.5897\n",
            "INFO:tensorflow:global_step/sec: 0.822739\n",
            "I0412 17:13:10.055662 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.822739\n",
            "INFO:tensorflow:examples/sec: 52.6553\n",
            "I0412 17:13:10.056108 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6553\n",
            "INFO:tensorflow:global_step/sec: 0.820266\n",
            "I0412 17:13:11.274753 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.820266\n",
            "INFO:tensorflow:examples/sec: 52.497\n",
            "I0412 17:13:11.275157 140454666205056 tpu_estimator.py:2308] examples/sec: 52.497\n",
            "INFO:tensorflow:global_step/sec: 0.824868\n",
            "I0412 17:13:12.487063 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.824868\n",
            "INFO:tensorflow:examples/sec: 52.7915\n",
            "I0412 17:13:12.487352 140454666205056 tpu_estimator.py:2308] examples/sec: 52.7915\n",
            "INFO:tensorflow:global_step/sec: 0.820779\n",
            "I0412 17:13:13.705405 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.820779\n",
            "INFO:tensorflow:examples/sec: 52.5299\n",
            "I0412 17:13:13.705944 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5299\n",
            "INFO:tensorflow:global_step/sec: 0.821044\n",
            "I0412 17:13:14.923397 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.821044\n",
            "INFO:tensorflow:examples/sec: 52.5468\n",
            "I0412 17:13:14.923721 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5468\n",
            "INFO:tensorflow:global_step/sec: 0.817528\n",
            "I0412 17:13:16.146627 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.817528\n",
            "INFO:tensorflow:examples/sec: 52.3218\n",
            "I0412 17:13:16.146925 140454666205056 tpu_estimator.py:2308] examples/sec: 52.3218\n",
            "INFO:tensorflow:global_step/sec: 0.819083\n",
            "I0412 17:13:17.367585 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.819083\n",
            "INFO:tensorflow:examples/sec: 52.4213\n",
            "I0412 17:13:17.367893 140454666205056 tpu_estimator.py:2308] examples/sec: 52.4213\n",
            "INFO:tensorflow:global_step/sec: 0.835635\n",
            "I0412 17:13:18.564173 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.835635\n",
            "INFO:tensorflow:examples/sec: 53.4807\n",
            "I0412 17:13:18.564462 140454666205056 tpu_estimator.py:2308] examples/sec: 53.4807\n",
            "INFO:tensorflow:global_step/sec: 0.821151\n",
            "I0412 17:13:19.781957 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.821151\n",
            "INFO:tensorflow:examples/sec: 52.5537\n",
            "I0412 17:13:19.782396 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5537\n",
            "INFO:tensorflow:global_step/sec: 0.822234\n",
            "I0412 17:13:20.998162 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.822234\n",
            "INFO:tensorflow:examples/sec: 52.623\n",
            "I0412 17:13:20.998433 140454666205056 tpu_estimator.py:2308] examples/sec: 52.623\n",
            "INFO:tensorflow:global_step/sec: 0.820216\n",
            "I0412 17:13:22.217370 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.820216\n",
            "INFO:tensorflow:examples/sec: 52.4938\n",
            "I0412 17:13:22.217929 140454666205056 tpu_estimator.py:2308] examples/sec: 52.4938\n",
            "INFO:tensorflow:global_step/sec: 0.818056\n",
            "I0412 17:13:23.439785 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.818056\n",
            "INFO:tensorflow:examples/sec: 52.3556\n",
            "I0412 17:13:23.440093 140454666205056 tpu_estimator.py:2308] examples/sec: 52.3556\n",
            "INFO:tensorflow:global_step/sec: 0.822116\n",
            "I0412 17:13:24.656139 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.822116\n",
            "INFO:tensorflow:examples/sec: 52.6154\n",
            "I0412 17:13:24.656424 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6154\n",
            "INFO:tensorflow:global_step/sec: 0.819624\n",
            "I0412 17:13:25.876188 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.819624\n",
            "INFO:tensorflow:examples/sec: 52.4559\n",
            "I0412 17:13:25.876479 140454666205056 tpu_estimator.py:2308] examples/sec: 52.4559\n",
            "INFO:tensorflow:global_step/sec: 0.817462\n",
            "I0412 17:13:27.099487 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.817462\n",
            "INFO:tensorflow:examples/sec: 52.3176\n",
            "I0412 17:13:27.099785 140454666205056 tpu_estimator.py:2308] examples/sec: 52.3176\n",
            "INFO:tensorflow:global_step/sec: 0.819652\n",
            "I0412 17:13:28.319604 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.819652\n",
            "INFO:tensorflow:examples/sec: 52.4577\n",
            "I0412 17:13:28.319922 140454666205056 tpu_estimator.py:2308] examples/sec: 52.4577\n",
            "INFO:tensorflow:global_step/sec: 0.824364\n",
            "I0412 17:13:29.532628 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.824364\n",
            "INFO:tensorflow:examples/sec: 52.7593\n",
            "I0412 17:13:29.532919 140454666205056 tpu_estimator.py:2308] examples/sec: 52.7593\n",
            "INFO:tensorflow:global_step/sec: 0.825451\n",
            "I0412 17:13:30.744048 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.825451\n",
            "INFO:tensorflow:examples/sec: 52.8289\n",
            "I0412 17:13:30.744369 140454666205056 tpu_estimator.py:2308] examples/sec: 52.8289\n",
            "INFO:tensorflow:global_step/sec: 0.836737\n",
            "I0412 17:13:31.939177 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.836737\n",
            "INFO:tensorflow:examples/sec: 53.5512\n",
            "I0412 17:13:31.939523 140454666205056 tpu_estimator.py:2308] examples/sec: 53.5512\n",
            "INFO:tensorflow:global_step/sec: 0.82122\n",
            "I0412 17:13:33.156886 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.82122\n",
            "INFO:tensorflow:examples/sec: 52.5581\n",
            "I0412 17:13:33.157207 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5581\n",
            "INFO:tensorflow:global_step/sec: 0.820554\n",
            "I0412 17:13:34.375616 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.820554\n",
            "INFO:tensorflow:examples/sec: 52.5154\n",
            "I0412 17:13:34.375955 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5154\n",
            "INFO:tensorflow:global_step/sec: 0.814253\n",
            "I0412 17:13:35.603746 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.814253\n",
            "INFO:tensorflow:examples/sec: 52.1122\n",
            "I0412 17:13:35.604077 140454666205056 tpu_estimator.py:2308] examples/sec: 52.1122\n",
            "INFO:tensorflow:global_step/sec: 0.82057\n",
            "I0412 17:13:36.822323 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.82057\n",
            "INFO:tensorflow:examples/sec: 52.5165\n",
            "I0412 17:13:36.822822 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5165\n",
            "INFO:tensorflow:global_step/sec: 0.840773\n",
            "I0412 17:13:38.011767 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.840773\n",
            "INFO:tensorflow:examples/sec: 53.8095\n",
            "I0412 17:13:38.012052 140454666205056 tpu_estimator.py:2308] examples/sec: 53.8095\n",
            "INFO:tensorflow:global_step/sec: 0.828957\n",
            "I0412 17:13:39.218094 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.828957\n",
            "INFO:tensorflow:examples/sec: 53.0532\n",
            "I0412 17:13:39.218384 140454666205056 tpu_estimator.py:2308] examples/sec: 53.0532\n",
            "INFO:tensorflow:global_step/sec: 0.822073\n",
            "I0412 17:13:40.434497 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.822073\n",
            "INFO:tensorflow:examples/sec: 52.6127\n",
            "I0412 17:13:40.435021 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6127\n",
            "INFO:tensorflow:global_step/sec: 0.820329\n",
            "I0412 17:13:41.653594 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.820329\n",
            "INFO:tensorflow:examples/sec: 52.5011\n",
            "I0412 17:13:41.654063 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5011\n",
            "INFO:tensorflow:global_step/sec: 0.821702\n",
            "I0412 17:13:42.870582 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.821702\n",
            "INFO:tensorflow:examples/sec: 52.5889\n",
            "I0412 17:13:42.871113 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5889\n",
            "INFO:tensorflow:global_step/sec: 0.819252\n",
            "I0412 17:13:44.091131 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.819252\n",
            "INFO:tensorflow:examples/sec: 52.4322\n",
            "I0412 17:13:44.091614 140454666205056 tpu_estimator.py:2308] examples/sec: 52.4322\n",
            "INFO:tensorflow:global_step/sec: 0.821389\n",
            "I0412 17:13:45.308584 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.821389\n",
            "INFO:tensorflow:examples/sec: 52.5689\n",
            "I0412 17:13:45.309037 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5689\n",
            "INFO:tensorflow:global_step/sec: 0.826504\n",
            "I0412 17:13:46.518496 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.826504\n",
            "INFO:tensorflow:examples/sec: 52.8962\n",
            "I0412 17:13:46.518823 140454666205056 tpu_estimator.py:2308] examples/sec: 52.8962\n",
            "INFO:tensorflow:global_step/sec: 0.828847\n",
            "I0412 17:13:47.724999 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.828847\n",
            "INFO:tensorflow:examples/sec: 53.0462\n",
            "I0412 17:13:47.725301 140454666205056 tpu_estimator.py:2308] examples/sec: 53.0462\n",
            "INFO:tensorflow:global_step/sec: 0.827733\n",
            "I0412 17:13:48.933161 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.827733\n",
            "INFO:tensorflow:examples/sec: 52.9749\n",
            "I0412 17:13:48.933695 140454666205056 tpu_estimator.py:2308] examples/sec: 52.9749\n",
            "INFO:tensorflow:global_step/sec: 0.823207\n",
            "I0412 17:13:50.147876 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.823207\n",
            "INFO:tensorflow:examples/sec: 52.6853\n",
            "I0412 17:13:50.148311 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6853\n",
            "INFO:tensorflow:global_step/sec: 0.822849\n",
            "I0412 17:13:51.363194 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.822849\n",
            "INFO:tensorflow:examples/sec: 52.6623\n",
            "I0412 17:13:51.363526 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6623\n",
            "INFO:tensorflow:global_step/sec: 0.836481\n",
            "I0412 17:13:52.558632 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.836481\n",
            "INFO:tensorflow:examples/sec: 53.5348\n",
            "I0412 17:13:52.558907 140454666205056 tpu_estimator.py:2308] examples/sec: 53.5348\n",
            "INFO:tensorflow:global_step/sec: 0.840065\n",
            "I0412 17:13:53.749066 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.840065\n",
            "INFO:tensorflow:examples/sec: 53.7641\n",
            "I0412 17:13:53.749359 140454666205056 tpu_estimator.py:2308] examples/sec: 53.7641\n",
            "INFO:tensorflow:global_step/sec: 0.826817\n",
            "I0412 17:13:54.958482 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.826817\n",
            "INFO:tensorflow:examples/sec: 52.9163\n",
            "I0412 17:13:54.958790 140454666205056 tpu_estimator.py:2308] examples/sec: 52.9163\n",
            "INFO:tensorflow:global_step/sec: 0.832971\n",
            "I0412 17:13:56.159021 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.832971\n",
            "INFO:tensorflow:examples/sec: 53.3102\n",
            "I0412 17:13:56.159495 140454666205056 tpu_estimator.py:2308] examples/sec: 53.3102\n",
            "INFO:tensorflow:global_step/sec: 0.839319\n",
            "I0412 17:13:57.350471 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.839319\n",
            "INFO:tensorflow:examples/sec: 53.7164\n",
            "I0412 17:13:57.350988 140454666205056 tpu_estimator.py:2308] examples/sec: 53.7164\n",
            "INFO:tensorflow:global_step/sec: 0.825347\n",
            "I0412 17:13:58.562105 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.825347\n",
            "INFO:tensorflow:examples/sec: 52.8222\n",
            "I0412 17:13:58.562621 140454666205056 tpu_estimator.py:2308] examples/sec: 52.8222\n",
            "INFO:tensorflow:global_step/sec: 0.841411\n",
            "I0412 17:13:59.750608 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.841411\n",
            "INFO:tensorflow:examples/sec: 53.8503\n",
            "I0412 17:13:59.751047 140454666205056 tpu_estimator.py:2308] examples/sec: 53.8503\n",
            "INFO:tensorflow:global_step/sec: 0.838055\n",
            "I0412 17:14:00.943824 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.838055\n",
            "INFO:tensorflow:examples/sec: 53.6355\n",
            "I0412 17:14:00.944162 140454666205056 tpu_estimator.py:2308] examples/sec: 53.6355\n",
            "INFO:tensorflow:global_step/sec: 0.823268\n",
            "I0412 17:14:02.158473 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.823268\n",
            "INFO:tensorflow:examples/sec: 52.6891\n",
            "I0412 17:14:02.158796 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6891\n",
            "INFO:tensorflow:global_step/sec: 0.820251\n",
            "I0412 17:14:03.377672 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.820251\n",
            "INFO:tensorflow:examples/sec: 52.4961\n",
            "I0412 17:14:03.378167 140454666205056 tpu_estimator.py:2308] examples/sec: 52.4961\n",
            "INFO:tensorflow:global_step/sec: 0.823907\n",
            "I0412 17:14:04.591372 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.823907\n",
            "INFO:tensorflow:examples/sec: 52.7301\n",
            "I0412 17:14:04.591810 140454666205056 tpu_estimator.py:2308] examples/sec: 52.7301\n",
            "INFO:tensorflow:global_step/sec: 0.843167\n",
            "I0412 17:14:05.777342 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.843167\n",
            "INFO:tensorflow:examples/sec: 53.9627\n",
            "I0412 17:14:05.777681 140454666205056 tpu_estimator.py:2308] examples/sec: 53.9627\n",
            "INFO:tensorflow:global_step/sec: 0.831393\n",
            "I0412 17:14:06.980102 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.831393\n",
            "INFO:tensorflow:examples/sec: 53.2092\n",
            "I0412 17:14:06.980974 140454666205056 tpu_estimator.py:2308] examples/sec: 53.2092\n",
            "INFO:tensorflow:global_step/sec: 0.84243\n",
            "I0412 17:14:08.167214 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.84243\n",
            "INFO:tensorflow:examples/sec: 53.9155\n",
            "I0412 17:14:08.167611 140454666205056 tpu_estimator.py:2308] examples/sec: 53.9155\n",
            "INFO:tensorflow:global_step/sec: 0.822912\n",
            "I0412 17:14:09.382360 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.822912\n",
            "INFO:tensorflow:examples/sec: 52.6664\n",
            "I0412 17:14:09.383607 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6664\n",
            "INFO:tensorflow:global_step/sec: 0.819351\n",
            "I0412 17:14:10.602857 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.819351\n",
            "INFO:tensorflow:examples/sec: 52.4384\n",
            "I0412 17:14:10.603340 140454666205056 tpu_estimator.py:2308] examples/sec: 52.4384\n",
            "INFO:tensorflow:global_step/sec: 0.837116\n",
            "I0412 17:14:11.797498 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.837116\n",
            "INFO:tensorflow:examples/sec: 53.5754\n",
            "I0412 17:14:11.798027 140454666205056 tpu_estimator.py:2308] examples/sec: 53.5754\n",
            "INFO:tensorflow:global_step/sec: 0.832837\n",
            "I0412 17:14:12.998136 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.832837\n",
            "INFO:tensorflow:examples/sec: 53.3016\n",
            "I0412 17:14:12.998636 140454666205056 tpu_estimator.py:2308] examples/sec: 53.3016\n",
            "INFO:tensorflow:global_step/sec: 0.829671\n",
            "I0412 17:14:14.203427 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.829671\n",
            "INFO:tensorflow:examples/sec: 53.0989\n",
            "I0412 17:14:14.203888 140454666205056 tpu_estimator.py:2308] examples/sec: 53.0989\n",
            "INFO:tensorflow:global_step/sec: 0.830045\n",
            "I0412 17:14:15.408226 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.830045\n",
            "INFO:tensorflow:examples/sec: 53.1229\n",
            "I0412 17:14:15.408721 140454666205056 tpu_estimator.py:2308] examples/sec: 53.1229\n",
            "INFO:tensorflow:global_step/sec: 0.841144\n",
            "I0412 17:14:16.597045 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.841144\n",
            "INFO:tensorflow:examples/sec: 53.8332\n",
            "I0412 17:14:16.597542 140454666205056 tpu_estimator.py:2308] examples/sec: 53.8332\n",
            "INFO:tensorflow:global_step/sec: 0.821792\n",
            "I0412 17:14:17.813929 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.821792\n",
            "INFO:tensorflow:examples/sec: 52.5947\n",
            "I0412 17:14:17.814241 140454666205056 tpu_estimator.py:2308] examples/sec: 52.5947\n",
            "INFO:tensorflow:global_step/sec: 0.824654\n",
            "I0412 17:14:19.026571 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.824654\n",
            "INFO:tensorflow:examples/sec: 52.7778\n",
            "I0412 17:14:19.027085 140454666205056 tpu_estimator.py:2308] examples/sec: 52.7778\n",
            "INFO:tensorflow:global_step/sec: 0.822385\n",
            "I0412 17:14:20.242586 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.822385\n",
            "INFO:tensorflow:examples/sec: 52.6326\n",
            "I0412 17:14:20.243119 140454666205056 tpu_estimator.py:2308] examples/sec: 52.6326\n",
            "INFO:tensorflow:global_step/sec: 0.824263\n",
            "I0412 17:14:21.455740 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.824263\n",
            "INFO:tensorflow:examples/sec: 52.7528\n",
            "I0412 17:14:21.456257 140454666205056 tpu_estimator.py:2308] examples/sec: 52.7528\n",
            "INFO:tensorflow:global_step/sec: 0.828442\n",
            "I0412 17:14:22.662798 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.828442\n",
            "INFO:tensorflow:examples/sec: 53.0203\n",
            "I0412 17:14:22.663110 140454666205056 tpu_estimator.py:2308] examples/sec: 53.0203\n",
            "INFO:tensorflow:global_step/sec: 0.83131\n",
            "I0412 17:14:23.865771 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.83131\n",
            "INFO:tensorflow:examples/sec: 53.2038\n",
            "I0412 17:14:23.866259 140454666205056 tpu_estimator.py:2308] examples/sec: 53.2038\n",
            "INFO:tensorflow:global_step/sec: 0.831676\n",
            "I0412 17:14:25.068115 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.831676\n",
            "INFO:tensorflow:examples/sec: 53.2273\n",
            "I0412 17:14:25.068422 140454666205056 tpu_estimator.py:2308] examples/sec: 53.2273\n",
            "INFO:tensorflow:global_step/sec: 0.826447\n",
            "I0412 17:14:26.278106 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.826447\n",
            "INFO:tensorflow:examples/sec: 52.8926\n",
            "I0412 17:14:26.278408 140454666205056 tpu_estimator.py:2308] examples/sec: 52.8926\n",
            "INFO:tensorflow:global_step/sec: 0.828608\n",
            "I0412 17:14:27.484977 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.828608\n",
            "INFO:tensorflow:examples/sec: 53.0309\n",
            "I0412 17:14:27.485316 140454666205056 tpu_estimator.py:2308] examples/sec: 53.0309\n",
            "INFO:tensorflow:global_step/sec: 0.831545\n",
            "I0412 17:14:28.687562 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.831545\n",
            "INFO:tensorflow:examples/sec: 53.2189\n",
            "I0412 17:14:28.688050 140454666205056 tpu_estimator.py:2308] examples/sec: 53.2189\n",
            "INFO:tensorflow:global_step/sec: 0.82347\n",
            "I0412 17:14:29.901906 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.82347\n",
            "INFO:tensorflow:examples/sec: 52.7021\n",
            "I0412 17:14:29.902200 140454666205056 tpu_estimator.py:2308] examples/sec: 52.7021\n",
            "INFO:tensorflow:global_step/sec: 0.839193\n",
            "I0412 17:14:31.093596 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.839193\n",
            "INFO:tensorflow:examples/sec: 53.7083\n",
            "I0412 17:14:31.093883 140454666205056 tpu_estimator.py:2308] examples/sec: 53.7083\n",
            "INFO:tensorflow:global_step/sec: 0.82975\n",
            "I0412 17:14:32.298755 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.82975\n",
            "INFO:tensorflow:examples/sec: 53.104\n",
            "I0412 17:14:32.299053 140454666205056 tpu_estimator.py:2308] examples/sec: 53.104\n",
            "INFO:tensorflow:global_step/sec: 0.849798\n",
            "I0412 17:14:33.475465 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.849798\n",
            "INFO:tensorflow:examples/sec: 54.3871\n",
            "I0412 17:14:33.475957 140454666205056 tpu_estimator.py:2308] examples/sec: 54.3871\n",
            "INFO:tensorflow:global_step/sec: 0.835879\n",
            "I0412 17:14:34.671827 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.835879\n",
            "INFO:tensorflow:examples/sec: 53.4962\n",
            "I0412 17:14:34.672319 140454666205056 tpu_estimator.py:2308] examples/sec: 53.4962\n",
            "INFO:tensorflow:global_step/sec: 0.832896\n",
            "I0412 17:14:35.872443 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.832896\n",
            "INFO:tensorflow:examples/sec: 53.3053\n",
            "I0412 17:14:35.872987 140454666205056 tpu_estimator.py:2308] examples/sec: 53.3053\n",
            "INFO:tensorflow:global_step/sec: 0.832846\n",
            "I0412 17:14:37.073163 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.832846\n",
            "INFO:tensorflow:examples/sec: 53.3022\n",
            "I0412 17:14:37.073739 140454666205056 tpu_estimator.py:2308] examples/sec: 53.3022\n",
            "INFO:tensorflow:global_step/sec: 0.843956\n",
            "I0412 17:14:38.258097 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.843956\n",
            "INFO:tensorflow:examples/sec: 54.0132\n",
            "I0412 17:14:38.258619 140454666205056 tpu_estimator.py:2308] examples/sec: 54.0132\n",
            "INFO:tensorflow:global_step/sec: 0.825747\n",
            "I0412 17:14:39.469137 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.825747\n",
            "INFO:tensorflow:examples/sec: 52.8478\n",
            "I0412 17:14:39.469547 140454666205056 tpu_estimator.py:2308] examples/sec: 52.8478\n",
            "INFO:tensorflow:global_step/sec: 0.830152\n",
            "I0412 17:14:40.673749 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.830152\n",
            "INFO:tensorflow:examples/sec: 53.1297\n",
            "I0412 17:14:40.674061 140454666205056 tpu_estimator.py:2308] examples/sec: 53.1297\n",
            "INFO:tensorflow:global_step/sec: 0.830184\n",
            "I0412 17:14:41.878209 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.830184\n",
            "INFO:tensorflow:examples/sec: 53.1318\n",
            "I0412 17:14:41.878747 140454666205056 tpu_estimator.py:2308] examples/sec: 53.1318\n",
            "INFO:tensorflow:global_step/sec: 0.839029\n",
            "I0412 17:14:43.070068 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.839029\n",
            "INFO:tensorflow:examples/sec: 53.6979\n",
            "I0412 17:14:43.070562 140454666205056 tpu_estimator.py:2308] examples/sec: 53.6979\n",
            "INFO:tensorflow:global_step/sec: 0.838816\n",
            "I0412 17:14:44.262241 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.838816\n",
            "INFO:tensorflow:examples/sec: 53.6842\n",
            "I0412 17:14:44.262742 140454666205056 tpu_estimator.py:2308] examples/sec: 53.6842\n",
            "INFO:tensorflow:global_step/sec: 0.848838\n",
            "I0412 17:14:45.440297 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.848838\n",
            "INFO:tensorflow:examples/sec: 54.3256\n",
            "I0412 17:14:45.440822 140454666205056 tpu_estimator.py:2308] examples/sec: 54.3256\n",
            "INFO:tensorflow:global_step/sec: 0.827618\n",
            "I0412 17:14:46.648631 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.827618\n",
            "INFO:tensorflow:examples/sec: 52.9676\n",
            "I0412 17:14:46.649151 140454666205056 tpu_estimator.py:2308] examples/sec: 52.9676\n",
            "INFO:tensorflow:global_step/sec: 0.834016\n",
            "I0412 17:14:47.847637 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.834016\n",
            "INFO:tensorflow:examples/sec: 53.377\n",
            "I0412 17:14:47.848156 140454666205056 tpu_estimator.py:2308] examples/sec: 53.377\n",
            "INFO:tensorflow:global_step/sec: 0.826722\n",
            "I0412 17:14:49.057191 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.826722\n",
            "INFO:tensorflow:examples/sec: 52.9102\n",
            "I0412 17:14:49.057491 140454666205056 tpu_estimator.py:2308] examples/sec: 52.9102\n",
            "INFO:tensorflow:global_step/sec: 0.826331\n",
            "I0412 17:14:50.267377 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.826331\n",
            "INFO:tensorflow:examples/sec: 52.8852\n",
            "I0412 17:14:50.267910 140454666205056 tpu_estimator.py:2308] examples/sec: 52.8852\n",
            "INFO:tensorflow:global_step/sec: 0.848203\n",
            "I0412 17:14:51.446359 140454666205056 tpu_estimator.py:2307] global_step/sec: 0.848203\n",
            "INFO:tensorflow:examples/sec: 54.285\n",
            "I0412 17:14:51.446919 140454666205056 tpu_estimator.py:2308] examples/sec: 54.285\n",
            "INFO:tensorflow:training_loop marked as finished\n",
            "I0412 17:14:52.731193 140454666205056 error_handling.py:101] training_loop marked as finished\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/NLP/model/run_pretraining.py\", line 577, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 312, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 258, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/drive/MyDrive/NLP/model/run_pretraining.py\", line 534, in main\n",
            "    estimator.train(input_fn=train_input_fn, max_steps=FLAGS.num_train_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py\", line 3030, in train\n",
            "    saving_listeners=saving_listeners)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 370, in train\n",
            "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1161, in _train_model\n",
            "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1195, in _train_model_default\n",
            "    saving_listeners)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1494, in _train_with_estimator_spec\n",
            "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 754, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1259, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1345, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1418, in run\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/monitored_session.py\", line 1176, in run\n",
            "    return self._sess.run(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/drive/MyDrive/NLP/model/run_pretraining.py\" \\\n",
        "    --input_file \"/content/drive/MyDrive/NLP/model/tf_examples\" \\\n",
        "    --output_dir \"/content/drive/MyDrive/NLP/model\" \\\n",
        "    --albert_config_file \"/content/drive/MyDrive/NLP/model/albert_config.json\" \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --train_batch_size=64 \\\n",
        "    --eval_batch_size=32 \\\n",
        "    --max_seq_length 50 \\\n",
        "    --max_predictions_per_seq 8 \\\n",
        "    --optimizer 'lamb' \\\n",
        "    --learning_rate .00176 \\\n",
        "    --num_train_steps 100000 \\\n",
        "    --num_warmup_steps 1000 \\\n",
        "    --save_checkpoints_steps 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjhSZOd4HU0k"
      },
      "source": [
        "### Converting Tensorflow Checkpoint file to Pytorch dump\n",
        "To use the HuggingFace library to realize our trained ALBERT model we need to convert our tensorflow checkpoint file to a pytorch dump."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "Zu7JFNY1TIfv",
        "outputId": "c2eba96a-79ab-4372-e530-7e9130eca0e3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5ce7433e7b63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_dump_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mconvert_tf_checkpoint_to_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.ckpt-100000'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'albert_config.json'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m'pytorch_model.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-5ce7433e7b63>\u001b[0m in \u001b[0;36mconvert_tf_checkpoint_to_pytorch\u001b[0;34m(tf_checkpoint_path, albert_config_file, pytorch_dump_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_tf_checkpoint_to_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_checkpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malbert_config_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_dump_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Initialise PyTorch model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlbertConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malbert_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Building PyTorch model from configuration: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlbertForPreTraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \"\"\"\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_dict_from_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'albert_config.json'"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import torch\n",
        "from transformers import AlbertConfig, AlbertForPreTraining, load_tf_weights_in_albert\n",
        "\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "\n",
        "def convert_tf_checkpoint_to_pytorch(tf_checkpoint_path, albert_config_file, pytorch_dump_path):\n",
        "    # Initialise PyTorch model\n",
        "    config = AlbertConfig.from_json_file(albert_config_file)\n",
        "    print(\"Building PyTorch model from configuration: {}\".format(str(config)))\n",
        "    model = AlbertForPreTraining(config)\n",
        "\n",
        "    # Load weights from tf checkpoint\n",
        "    load_tf_weights_in_albert(model, config, tf_checkpoint_path)\n",
        "\n",
        "    # Save pytorch-model\n",
        "    print(\"Save PyTorch model to {}\".format(pytorch_dump_path))\n",
        "    torch.save(model.state_dict(), pytorch_dump_path)\n",
        "\n",
        "convert_tf_checkpoint_to_pytorch('model.ckpt-100000','albert_config.json' , 'pytorch_model.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9qL_t8nHU0l"
      },
      "source": [
        "### Creating the trained ALBERT model\n",
        "Now that we have our pytorch_model.bin file with few steps we can make a functional model to help us generate embeddings for our docstrings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "4tuRMl1xHU0m",
        "outputId": "dc915527-9545-4c0c-cd10-6acdd3aa29d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-87f4cfb949c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Getting the albert tokenizer from HuggingFace library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0malbert_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlbertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'albert-base-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m    771\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0mfailed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecks\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfailed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: \nAlbertTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment.\n",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Getting the albert tokenizer from HuggingFace library\n",
        "albert_tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "9VeO0LKIHU0m",
        "outputId": "328918c0-8c20-446c-e579-df756b931f09"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m                 \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m                 \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RepoNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"404 Client Error: Repository Not Found for url: {request.url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EntryNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error: Repository Not Found for url: https://huggingface.co/./albert/resolve/main/config.json",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ad5240abe769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the weights and the configuration of our trained ALBERT model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlbertConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./albert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFAlbertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./albert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mfrom_pt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             logger.warning(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m             raise EnvironmentError(\n\u001b[0;32m--> 609\u001b[0;31m                 \u001b[0;34mf\"{pretrained_model_name_or_path} is not a local folder and is not a valid model identifier listed on \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models'\\nIf this is a private repository, make sure to pass a token having \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m                 \u001b[0;34m\"permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: ./albert is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
          ]
        }
      ],
      "source": [
        "# Loading the weights and the configuration of our trained ALBERT model\n",
        "config = AlbertConfig.from_pretrained('./albert', output_hidden_states=True)\n",
        "\n",
        "model = TFAlbertModel.from_pretrained('./albert', config=config,  from_pt=True)\n",
        "print(model.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4PuGdjIHU0m"
      },
      "source": [
        "### Generating Embeddings for Docstrings\n",
        "Now that our ALBERT model is ready we can churn out some docstring vectors from it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKvoUow3HqV1",
        "outputId": "2d614b4f-fef2-4e65-d6a3-ec8675e240bc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "o7G1Kgt7HU0m",
        "outputId": "62d9eb6a-d1ff-402c-cec9-6c37398c996a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0   index                            nwo  \\\n",
              "0       60914  425624      ElementalAlchemist/txircd   \n",
              "1       42269  262698                  cea-sec/miasm   \n",
              "2       16672  627555              att-comdev/armada   \n",
              "3       96804  491510  MahmoudAbdelRahman/GH_CPython   \n",
              "4       24375  205664         whitehorse-io/encarnia   \n",
              "\n",
              "                                                path           function_name  \\\n",
              "0                         txircd/module_interface.py            channelModes   \n",
              "1                          miasm2/arch/mips32/sem.py                     sra   \n",
              "2                                armada/cli/apply.py                   apply   \n",
              "3                         GrasshopperSyntax/plane.py  PlanePlaneIntersection   \n",
              "4  pyenv/lib/python2.7/site-packages/twisted/pair...        datagramReceived   \n",
              "\n",
              "   lineno                                  original_function  \\\n",
              "0      18  def channelModes():\\n    \"\"\"\\n\\t\\tReturns the ...   \n",
              "1     187  @sbuild.parse\\ndef sra(arg1, arg2, arg3):\\n   ...   \n",
              "2      28  @click.group()\\ndef apply():\\n    \"\"\" Apply ma...   \n",
              "3     300  def PlanePlaneIntersection(plane1, plane2):\\n ...   \n",
              "4      23  def datagramReceived():\\n    \"\"\"An Ethernet fr...   \n",
              "\n",
              "          function_tokens                                   docstring_tokens  \\\n",
              "0            channelmodes  returns the channel modes provided by the modu...   \n",
              "1                     sra                         shifts arg1 register value   \n",
              "2                   apply                          apply manifest to cluster   \n",
              "3  planeplaneintersection  calculates the intersection of two planes para...   \n",
              "4        datagramreceived                an ethernet frame has been received   \n",
              "\n",
              "                                                 url  function_tokens_count  \n",
              "0  https://github.com/ElementalAlchemist/txircd/b...                      1  \n",
              "1  https://github.com/cea-sec/miasm/blob/master/m...                      1  \n",
              "2  https://github.com/att-comdev/armada/blob/mast...                      1  \n",
              "3  https://github.com/MahmoudAbdelRahman/GH_CPyth...                      1  \n",
              "4  https://github.com/whitehorse-io/encarnia/blob...                      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06e4ddf6-fd6b-49fa-9602-2eb0eb0037bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>nwo</th>\n",
              "      <th>path</th>\n",
              "      <th>function_name</th>\n",
              "      <th>lineno</th>\n",
              "      <th>original_function</th>\n",
              "      <th>function_tokens</th>\n",
              "      <th>docstring_tokens</th>\n",
              "      <th>url</th>\n",
              "      <th>function_tokens_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60914</td>\n",
              "      <td>425624</td>\n",
              "      <td>ElementalAlchemist/txircd</td>\n",
              "      <td>txircd/module_interface.py</td>\n",
              "      <td>channelModes</td>\n",
              "      <td>18</td>\n",
              "      <td>def channelModes():\\n    \"\"\"\\n\\t\\tReturns the ...</td>\n",
              "      <td>channelmodes</td>\n",
              "      <td>returns the channel modes provided by the modu...</td>\n",
              "      <td>https://github.com/ElementalAlchemist/txircd/b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42269</td>\n",
              "      <td>262698</td>\n",
              "      <td>cea-sec/miasm</td>\n",
              "      <td>miasm2/arch/mips32/sem.py</td>\n",
              "      <td>sra</td>\n",
              "      <td>187</td>\n",
              "      <td>@sbuild.parse\\ndef sra(arg1, arg2, arg3):\\n   ...</td>\n",
              "      <td>sra</td>\n",
              "      <td>shifts arg1 register value</td>\n",
              "      <td>https://github.com/cea-sec/miasm/blob/master/m...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16672</td>\n",
              "      <td>627555</td>\n",
              "      <td>att-comdev/armada</td>\n",
              "      <td>armada/cli/apply.py</td>\n",
              "      <td>apply</td>\n",
              "      <td>28</td>\n",
              "      <td>@click.group()\\ndef apply():\\n    \"\"\" Apply ma...</td>\n",
              "      <td>apply</td>\n",
              "      <td>apply manifest to cluster</td>\n",
              "      <td>https://github.com/att-comdev/armada/blob/mast...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96804</td>\n",
              "      <td>491510</td>\n",
              "      <td>MahmoudAbdelRahman/GH_CPython</td>\n",
              "      <td>GrasshopperSyntax/plane.py</td>\n",
              "      <td>PlanePlaneIntersection</td>\n",
              "      <td>300</td>\n",
              "      <td>def PlanePlaneIntersection(plane1, plane2):\\n ...</td>\n",
              "      <td>planeplaneintersection</td>\n",
              "      <td>calculates the intersection of two planes para...</td>\n",
              "      <td>https://github.com/MahmoudAbdelRahman/GH_CPyth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24375</td>\n",
              "      <td>205664</td>\n",
              "      <td>whitehorse-io/encarnia</td>\n",
              "      <td>pyenv/lib/python2.7/site-packages/twisted/pair...</td>\n",
              "      <td>datagramReceived</td>\n",
              "      <td>23</td>\n",
              "      <td>def datagramReceived():\\n    \"\"\"An Ethernet fr...</td>\n",
              "      <td>datagramreceived</td>\n",
              "      <td>an ethernet frame has been received</td>\n",
              "      <td>https://github.com/whitehorse-io/encarnia/blob...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06e4ddf6-fd6b-49fa-9602-2eb0eb0037bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06e4ddf6-fd6b-49fa-9602-2eb0eb0037bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06e4ddf6-fd6b-49fa-9602-2eb0eb0037bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Load the train data\n",
        "data_path = '/content/drive/MyDrive/NLP/data/'\n",
        "\n",
        "train_df = pd.read_csv(data_path + 'train_sorted.csv')\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lJeZp_zUHU0n"
      },
      "outputs": [],
      "source": [
        "# Number of docstrings\n",
        "#print(len(train_df['docstring'].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7e43AcprHU0n"
      },
      "outputs": [],
      "source": [
        "avg_embeddings = []\n",
        "for count,item in enumerate(train_df['docstring'].values): #traverse thorugh all train data set docstrings\n",
        "    e = albert_tokenizer.encode(item, max_length=512)\n",
        "    input = tf.constant(e)[None, :]  # Batch size 1 \n",
        "    output = model(input)\n",
        "    v = [0]*768\n",
        "    for i in range(1, len(input[0])-1):\n",
        "        v = v + output[0][0][i].numpy()  # generate sentence vectors by averaging the word vectors\n",
        "    avg_embeddings.append(v/len(input[0])) #append all sentence vectors into a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsCjbNuMHU0n"
      },
      "outputs": [],
      "source": [
        "# Save the sentence embeddings in a .tsv file\n",
        "with open(\"avg_embeddings.tsv\",\"w+\",newline='') as my_csv:\n",
        "    csvWriter = csv.writer(my_csv,delimiter='\\t')\n",
        "    csvWriter.writerows(avg_embeddings)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Part-II Converting Docstrings to vectors.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}