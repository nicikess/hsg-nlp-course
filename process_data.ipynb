{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "mount_file_id": "1EJze86cE1sgX9TSSxevgeTChYxKVg9P6",
      "authorship_tag": "ABX9TyOAR03tn2wuk3sk31ZpCKEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicikess/hsg-nlp-course/blob/main/process_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DFtnHm_ltTfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SCRIPT SOURCE: https://github.com/microsoft/CodeBERT/blob/master/CodeBERT/codesearch/process_data.py"
      ],
      "metadata": {
        "id": "vAwwYvQFt7k7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hvI7l84wsnz0"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from more_itertools import chunked"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_str(string):\n",
        "    for char in ['\\r\\n', '\\r', '\\n']:\n",
        "        string = string.replace(char, ' ')\n",
        "    return string"
      ],
      "metadata": {
        "id": "KVAugX0msvh9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = '/content/drive/MyDrive/NLP/data/'"
      ],
      "metadata": {
        "id": "JvzAKd1bs21h"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_test_data(language, test_batch_size=1000):\n",
        "    path = os.path.join(DATA_DIR, '{}_test_0.jsonl.gz'.format(language))\n",
        "    print(path)\n",
        "    with gzip.open(path, 'r') as pf:\n",
        "        data = pf.readlines()  \n",
        "\n",
        "    idxs = np.arange(len(data))\n",
        "    data = np.array(data, dtype=np.object)\n",
        "\n",
        "    np.random.seed(0)   # set random seed so that random things are reproducible\n",
        "    np.random.shuffle(idxs)\n",
        "    data = data[idxs]\n",
        "    batched_data = chunked(data, test_batch_size)\n",
        "\n",
        "    print(\"start processing\")\n",
        "    for batch_idx, batch_data in enumerate(batched_data):\n",
        "        if len(batch_data) < test_batch_size:\n",
        "            break # the last batch is smaller than the others, exclude.\n",
        "        examples = []\n",
        "        for d_idx, d in enumerate(batch_data): \n",
        "            line_a = json.loads(str(d, encoding='utf-8'))\n",
        "            doc_token = ' '.join(line_a['docstring_tokens'])\n",
        "            for dd in batch_data:\n",
        "                line_b = json.loads(str(dd, encoding='utf-8'))\n",
        "                code_token = ' '.join([format_str(token) for token in line_b['code_tokens']])\n",
        "\n",
        "                example = (str(1), line_a['url'], line_b['url'], doc_token, code_token)\n",
        "                example = '<CODESPLIT>'.join(example)\n",
        "                examples.append(example)\n",
        "\n",
        "        data_path = os.path.join(DATA_DIR, 'test/{}'.format(language))\n",
        "        if not os.path.exists(data_path):\n",
        "            os.makedirs(data_path)\n",
        "        file_path = os.path.join(data_path, 'batch_{}.txt'.format(batch_idx))\n",
        "        print(file_path)\n",
        "        with open(file_path, 'w', encoding='utf-8') as f:\n",
        "            f.writelines('\\n'.join(examples))"
      ],
      "metadata": {
        "id": "rH_vQZjUszgj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    languages = ['python']\n",
        "    for lang in languages:\n",
        "        preprocess_test_data(lang)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7-CIIbAswbi",
        "outputId": "4ad6a678-7651-49be-a2f1-f604a89a8ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/NLP/data/python_test_0.jsonl.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start processing\n",
            "/content/drive/MyDrive/NLP/data/test/python/batch_0.txt\n",
            "/content/drive/MyDrive/NLP/data/test/python/batch_1.txt\n",
            "/content/drive/MyDrive/NLP/data/test/python/batch_2.txt\n"
          ]
        }
      ]
    }
  ]
}